{"meta":{"title":"CharlesBlog","subtitle":"","description":"","author":"Charles","url":"http://example.com","root":"/"},"pages":[{"title":"我的分类页","date":"2021-01-14T05:37:13.000Z","updated":"2021-01-14T05:37:52.981Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"music","date":"2021-06-09T06:14:15.000Z","updated":"2021-06-09T06:14:15.484Z","comments":true,"path":"music/index.html","permalink":"http://example.com/music/index.html","excerpt":"","text":""},{"title":"我的标签页","date":"2021-01-14T05:38:26.000Z","updated":"2021-01-14T05:39:00.600Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"我的小伙伴们","date":"2021-01-14T05:39:21.000Z","updated":"2021-01-14T05:39:55.004Z","comments":true,"path":"link/index.html","permalink":"http://example.com/link/index.html","excerpt":"","text":""},{"title":"","date":"2021-06-09T02:36:24.182Z","updated":"2021-06-09T02:36:24.181Z","comments":true,"path":"self/doutone.css","permalink":"http://example.com/self/doutone.css","excerpt":"","text":"/* Name: Duotone Light Author: Simurai, adapted from DuoTone themes for Atom (http://simurai.com/projects/2016/01/01/duotone-themes) Conversion: Bram de Haan (http://atelierbram.github.io/Base2Tone-prism/output/prism/prism-base2tone-morning-light.css) Generated with Base16 Builder (https://github.com/base16-builder/base16-builder) */ code[class*=\"language-\"], pre[class*=\"language-\"] { font-family: Consolas, Menlo, Monaco, \"Andale Mono WT\", \"Andale Mono\", \"Lucida Console\", \"Lucida Sans Typewriter\", \"DejaVu Sans Mono\", \"Bitstream Vera Sans Mono\", \"Liberation Mono\", \"Nimbus Mono L\", \"Courier New\", Courier, monospace; font-size: 14px; line-height: 1.375; direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; -moz-tab-size: 4; -o-tab-size: 4; tab-size: 4; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; background: #faf8f5; color: #728fcb; } pre > code[class*=\"language-\"] { font-size: 1em; } pre[class*=\"language-\"]::-moz-selection, pre[class*=\"language-\"] ::-moz-selection, code[class*=\"language-\"]::-moz-selection, code[class*=\"language-\"] ::-moz-selection { text-shadow: none; background: #faf8f5; } pre[class*=\"language-\"]::selection, pre[class*=\"language-\"] ::selection, code[class*=\"language-\"]::selection, code[class*=\"language-\"] ::selection { text-shadow: none; background: #faf8f5; } /* Code blocks */ pre[class*=\"language-\"] { padding: 1em; margin: .5em 0; overflow: auto; } /* Inline code */ :not(pre) > code[class*=\"language-\"] { padding: .1em; border-radius: .3em; } .token.comment, .token.prolog, .token.doctype, .token.cdata { color: #b6ad9a; } .token.punctuation { color: #b6ad9a; } .token.namespace { opacity: .7; } .token.tag, .token.operator, .token.number { color: #063289; } .token.property, .token.function { color: #b29762; } .token.tag-id, .token.selector, .token.atrule-id { color: #2d2006; } code.language-javascript, .token.attr-name { color: #896724; } code.language-css, code.language-scss, .token.boolean, .token.string, .token.entity, .token.url, .language-css .token.string, .language-scss .token.string, .style .token.string, .token.attr-value, .token.keyword, .token.control, .token.directive, .token.unit, .token.statement, .token.regex, .token.atrule { color: #728fcb; } .token.placeholder, .token.variable { color: #93abdc; } .token.deleted { text-decoration: line-through; } .token.inserted { border-bottom: 1px dotted #2d2006; text-decoration: none; } .token.italic { font-style: italic; } .token.important, .token.bold { font-weight: bold; } .token.important { color: #896724; } .token.entity { cursor: help; } pre > code.highlight { outline: .4em solid #896724; outline-offset: .4em; } /* overrides color-values for the Line Numbers plugin * http://prismjs.com/plugins/line-numbers/ */ .line-numbers .line-numbers-rows { border-right-color: #ece8de; } .line-numbers-rows > span:before { color: #cdc4b1; } /* overrides color-values for the Line Highlight plugin * http://prismjs.com/plugins/line-highlight/ */ .line-highlight { background: rgba(45, 32, 6, 0.2); background: -webkit-linear-gradient(left, rgba(45, 32, 6, 0.2) 70%, rgba(45, 32, 6, 0)); background: linear-gradient(to right, rgba(45, 32, 6, 0.2) 70%, rgba(45, 32, 6, 0)); } :root { --hl-color: #728fcb; --hl-bg: #faf8f5; --hltools-bg: xxxxxxx; --hltools-color: xxxxxxx; --hlnumber-bg: xxxxxxx; --hlnumber-color: xxxxxxxx; --hlscrollbar-bg: xxxxx; --hlexpand-bg: xxxxxxx } code[class*=\"language-\"], pre[class*=\"language-\"] { font-family: Consolas, Menlo, Monaco, \"Andale Mono WT\", \"Andale Mono\", \"Lucida Console\", \"Lucida Sans Typewriter\", \"DejaVu Sans Mono\", \"Bitstream Vera Sans Mono\", \"Liberation Mono\", \"Nimbus Mono L\", \"Courier New\", Courier, monospace; font-size: 14px; line-height: 1.375; direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; -moz-tab-size: 4; -o-tab-size: 4; tab-size: 4; -webkit-hyphens: none; -moz-hyphens: none; -ms-hyphens: none; hyphens: none; background: #faf8f5; color: #728fcb; } pre > code[class*=\"language-\"] { font-size: 1em; } pre[class*=\"language-\"]::-moz-selection, pre[class*=\"language-\"] ::-moz-selection, code[class*=\"language-\"]::-moz-selection, code[class*=\"language-\"] ::-moz-selection { text-shadow: none; background: #faf8f5; } pre[class*=\"language-\"]::selection, pre[class*=\"language-\"] ::selection, code[class*=\"language-\"]::selection, code[class*=\"language-\"] ::selection { text-shadow: none; background: #faf8f5; } /* Code blocks */ pre[class*=\"language-\"] { padding: 1em; margin: .5em 0; overflow: auto; } /* Inline code */ :not(pre) > code[class*=\"language-\"] { padding: .1em; border-radius: .3em; } /* ------------------------------------- */ /* 到这里为止，可以删除 */ .token.comment, .token.prolog, .token.doctype, .token.cdata { color: #b6ad9a; } .token.punctuation { color: #b6ad9a; } .token.namespace { opacity: .7; } .token.tag, .token.operator, .token.number { color: #063289; } .token.property, .token.function { color: #b29762; } .token.tag-id, .token.selector, .token.atrule-id { color: #2d2006; } code.language-javascript, .token.attr-name { color: #896724; } code.language-css, code.language-scss, .token.boolean, .token.string, .token.entity, .token.url, .language-css .token.string, .language-scss .token.string, .style .token.string, .token.attr-value, .token.keyword, .token.control, .token.directive, .token.unit, .token.statement, .token.regex, .token.atrule { color: #728fcb; } .token.placeholder, .token.variable { color: #93abdc; } .token.deleted { text-decoration: line-through; } .token.inserted { border-bottom: 1px dotted #2d2006; text-decoration: none; } .token.italic { font-style: italic; } .token.important, .token.bold { font-weight: bold; } .token.important { color: #896724; } .token.entity { cursor: help; } pre > code.highlight { outline: .4em solid #896724; outline-offset: .4em; } /* overrides color-values for the Line Numbers plugin * http://prismjs.com/plugins/line-numbers/ */ .line-numbers .line-numbers-rows { border-right-color: #ece8de; } .line-numbers-rows > span:before { color: #cdc4b1; } /* overrides color-values for the Line Highlight plugin * http://prismjs.com/plugins/line-highlight/ */ .line-highlight { background: rgba(45, 32, 6, 0.2); background: -webkit-linear-gradient(left, rgba(45, 32, 6, 0.2) 70%, rgba(45, 32, 6, 0)); background: linear-gradient(to right, rgba(45, 32, 6, 0.2) 70%, rgba(45, 32, 6, 0)); }"}],"posts":[{"title":"","slug":"深度学习基础","date":"2021-11-04T02:17:08.409Z","updated":"2021-11-04T02:17:08.409Z","comments":true,"path":"2021/11/04/深度学习基础/","link":"","permalink":"http://example.com/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/","excerpt":"","text":"","categories":[],"tags":[],"author":"Charles"},{"title":"特征工程-特征降维","slug":"特征工程-特征降维","date":"2021-09-23T13:52:00.000Z","updated":"2021-09-23T13:56:09.187Z","comments":true,"path":"2021/09/23/特征工程-特征降维/","link":"","permalink":"http://example.com/2021/09/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/","excerpt":"","text":"","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"特征工程-特征降维","slug":"特征工程-特征降维","permalink":"http://example.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/"}],"author":"Charles"},{"title":"特征工程-特征预处理","slug":"特征工程-特征预处理","date":"2021-09-20T13:12:00.000Z","updated":"2021-09-20T13:13:57.202Z","comments":true,"path":"2021/09/20/特征工程-特征预处理/","link":"","permalink":"http://example.com/2021/09/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/","excerpt":"","text":"什么是特征预处理特征预处理定义 scikit-learn的解释provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators. 翻译过来：通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程 为什么我们要进行归一化/标准化？ 特征的单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，容易影响（支配）目标结果，使得一些算法无法学习到其它的特征 举例：约会对象数据 我们需要用到一些方法进行无量纲化，使不同规格的数据转换到同一规格. 包含内容(数值型数据的无量纲化) 归一化 标准化特征处理API sklearn.preprocessing 归一化定义通过对原始数据进行变换把数据映射到(默认为[0,1])之间 公式 作用于每一列，max为一列的最大值，min为一列的最小值,那么X’’为最终结果，mx，mi分别为指定区间值默认mx为1,mi为0 API sklearn.preprocessing.MinMaxScaler (feature_range=(0,1)… ) MinMaxScalar.fit_transform(X)X:numpy array格式的数据[n_samples,n_features] 返回值：转换后的形状相同的array 数据计算我们对以下数据进行运算，保存的就是之前的约会对象数据1234540920,8.326976,0.953952,314488,7.153469,1.673904,226052,1.441871,0.805124,175136,13.147394,0.428964,138344,1.669788,0.134296,1 分析 实例化MinMaxScalar 通过fit_transform转换pandas as pd12345678910111213141516from sklearn.preprocessing import MinMaxScalerdef minmax_demo(): &quot;&quot;&quot; 归一化演示 :return: None &quot;&quot;&quot; data &#x3D; pd.read_csv(&quot;.&#x2F;data&#x2F;dating.txt&quot;) print(data) # 1、实例化一个转换器类 transfer &#x3D; MinMaxScaler(feature_range&#x3D;(2, 3)) # 2-3之间 # 2、调用fit_transform data &#x3D; transfer.fit_transform(data[[&#39;milage&#39;,&#39;Liters&#39;,&#39;Consumtime&#39;]]) print(&quot;最小值最大值归一化处理的结果：\\n&quot;, data) return None 返回结果Liters Consumtime target1234567891011121314151617180 40920 8.326976 0.953952 31 14488 7.153469 1.673904 22 26052 1.441871 0.805124 13 75136 13.147394 0.428964 1.. ... ... ... ...998 48111 9.134528 0.728045 3999 43757 7.882601 1.332446 3[1000 rows x 4 columns]最小值最大值归一化处理的结果： [[ 2.44832535 2.39805139 2.56233353] [ 2.15873259 2.34195467 2.98724416] [ 2.28542943 2.06892523 2.47449629] ..., [ 2.29115949 2.50910294 2.51079493] [ 2.52711097 2.43665451 2.4290048 ] [ 2.47940793 2.3768091 2.78571804]] 归一化总结因为最大值最小值是变化的，另外，最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差（健壮性），只适合传统精确小数据场景。怎么办？ 标准化定义通过对原始数据进行变换把数据变换到均值为0,标准差为1范围内 公式 作用于每一列，mean为平均值，σ为标准差 所以回到刚才异常点的地方，我们再来看看标准化 对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变 对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。 API sklearn.preprocessing.StandardScaler( ) 处理之后每列来说所有数据都聚集在均值0附近标准差差为1 StandardScaler.fit_transform(X) X:numpy array格式的数据[n_samples,n_features] 返回值：转换后的形状相同的array 数据计算同样对上面的数据进行处理 分析 实例化StandardScaler 通过fit_transform转换1234567891011121314151617181920import pandas as pdfrom sklearn.preprocessing import StandardScalerdef stand_demo(): &quot;&quot;&quot; 标准化演示 :return: None &quot;&quot;&quot; data &#x3D; pd.read_csv(&quot;dating.txt&quot;) print(data) # 1、实例化一个转换器类 transfer &#x3D; StandardScaler() # 2、调用fit_transform data &#x3D; transfer.fit_transform(data[[&#39;milage&#39;,&#39;Liters&#39;,&#39;Consumtime&#39;]]) print(&quot;标准化的结果:\\n&quot;, data) print(&quot;每一列特征的平均值：\\n&quot;, transfer.mean_) print(&quot;每一列特征的方差：\\n&quot;, transfer.var_) return None 返回结果：1234567891011121314151617181920212223 milage Liters Consumtime target0 40920 8.326976 0.953952 31 14488 7.153469 1.673904 22 26052 1.441871 0.805124 1.. ... ... ... ...997 26575 10.650102 0.866627 3998 48111 9.134528 0.728045 3999 43757 7.882601 1.332446 3[1000 rows x 4 columns]标准化的结果: [[ 0.33193158 0.41660188 0.24523407] [-0.87247784 0.13992897 1.69385734] [-0.34554872 -1.20667094 -0.05422437] ..., [-0.32171752 0.96431572 0.06952649] [ 0.65959911 0.60699509 -0.20931587] [ 0.46120328 0.31183342 1.00680598]]每一列特征的平均值： [ 3.36354210e+04 6.55996083e+00 8.32072997e-01]每一列特征的方差： [ 4.81628039e+08 1.79902874e+01 2.46999554e-01] 标准化总结在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"特征工程-特征预处理","slug":"特征工程-特征预处理","permalink":"http://example.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/"}],"author":"Charles"},{"title":"数据处理与特征工程-特征提取","slug":"进入机器学习","date":"2021-06-09T03:46:51.000Z","updated":"2021-09-20T13:13:54.345Z","comments":true,"path":"2021/06/09/进入机器学习/","link":"","permalink":"http://example.com/2021/06/09/%E8%BF%9B%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"console.error(\"Error: [hexo-tag-aplayer] Meting support is disabled, cannot resolve the meting tags properly.\"); 数据集可用数据集 公司内部、百度 数据接口（￥） 各种数据集 学习阶段可用的数据集 sklean kaggle UCIsklearn 数据集 导入数据集和工具库 123#导入sklearn数据包from sklearn.datasets import load_iris #导入鸢尾花数据集from sklearn.model_selection import train_test_split #导入模型划分 数据查看 1234567891011#字典格式total&#x3D;load_iris()#print(total)#数据目标值print(total.target_names)print(total.target)#数据内容（数据特征值）print(total.feature_names)print(total.data)#数据描述print(total.DESCR) 对数据集进行划分 1234#返回值 训练集 和 测试集x_train,x_test,y_train,y_test&#x3D;train_test_split(total.data,total.target,test_size&#x3D;0.24,random_state&#x3D;25)print(&quot;训练集特征值及目标值：\\n&quot;,x_train,&quot;\\n&quot;,y_train)print(&quot;测试集特征值及目标值：\\n&quot;,x_test,x_train) 特征工程 为什么需要特征工程 数据和特征决定了机器学习的上限，而模型和算法知识逼近这个上限而已 什么是特征工程 pandas ——&gt; 数据清洗、数据处理sklearn ——&gt; 特征工程 特征提取定义将任意数据（如文本或图像）转化为可用于机器学习的数字特征 注：特征值化是为了计算机更好的理解数据sklearn.feature_extraction（特征提取API） 特征提取的分类 字典特征提取（特征离散化） 文本特征提取 图像特征提取（深度学习） 字典特征提取 字典特征提取 ——&gt; 类型 ——&gt; one-hot编码 导入sklearn数据包123from sklearn.datasets import load_iris #导入鸢尾花数据集from sklearn.model_selection import train_test_split #导入模型划分from sklearn.feature_extraction import DictVectorizer #导入字典特征转换器 利用转化器进行特征提取123456789data&#x3D;[&#123;&#39;city&#39;:&#39;北京&#39;,&#39;temperature&#39;:100&#125;, &#123;&#39;city&#39;:&#39;上海&#39;,&#39;temperature&#39;:60&#125;, &#123;&#39;city&#39;:&#39;深圳&#39;,&#39;temperature&#39;:30&#125;]#1.实例化一个转化器类transfer&#x3D;DictVectorizer(sparse&#x3D;False)#sparse&#x3D;Ture 返回sparse矩阵（稀疏矩阵将非零值按位置返回）---&gt;可以提高效率#2.调用fit_transform()data_new&#x3D;transfer.fit_transform(data)print(transfer.get_feature_names())print(data_new) 中文文本特征提取 方法一：CountVectorizer统计每个样本特征词出现的个数 stop_words停用词 停用词表 1234567891011121314151617181920212223242526272829from sklearn.feature_extraction.text import CountVectorizer#导入文本特征转换器data&#x3D;[&quot;人生苦短我要学习深度学习，加油奥里给我里宝贝。&quot;, &quot;菏泽曹县666窝里宝贝。&quot;, &quot;我爱你桑桑。&quot;]data1&#x3D;&quot;我爱北京天安门&quot;#使用jieba切割文档（切割参数为字符串）&#39;&#39;&#39;a&#x3D;list(jieba.cut(data1))b&#x3D;&quot; &quot;.join(list(jieba.cut(data1)))print(a)print(type(a))print(b)print(type(b))&#39;&#39;&#39;#1.将中文文本进行分词data_new&#x3D;[]for sent in data: #a&#x3D;&quot; &quot;.join(list(jieba.cut(sent))) #print(a) data_new.append(&quot; &quot;.join(list(jieba.cut(sent))))print(data_new)#2.实现一个转化器类transfer&#x3D;CountVectorizer(stop_words&#x3D;[&quot;666&quot;,&quot;宝贝啊&quot;])#3.调用fit_transformdata_fin&#x3D;transfer.fit_transform(data_new)print(&quot;特征名字：\\n&quot;,transfer.get_feature_names())print(&quot;data_fin：\\n&quot;,data_fin.toarray()) 方法二：TfidfVectorize区别于方法一：更容易找到关键词（在其他文章出现很少，在本文中出现很多的词汇） TF —— 词频（term frequency） IDF —— 由总文件数目除以包括该词语之文件的数目，再到的商取以10为底的对数得到 TF-IDF=TF×IDF —— 重要程度 12345678910111213141516from sklearn.feature_extraction.text import TfidfVectorizerdata&#x3D;[&quot;人生苦短我要学习深度学习，加油奥里给我里宝贝。&quot;, &quot;菏泽曹县666窝里宝贝。&quot;, &quot;我爱你桑桑。&quot;]#1.将文本进行分词data_new&#x3D;[]for sent in data: data_new.append(&quot; &quot;.join(list(jieba.cut(sent))))#2.实例化一个转换器对象transfer&#x3D;TfidfVectorizer()#3.利用转换器对象进行数据分割data_fin&#x3D;transfer.fit_transform(data_new)print(&quot;特征名字：\\n&quot;,transfer.get_feature_names())print(&quot;data_fin：\\n&quot;,data_fin.toarray())","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"数据处理与特征工程-特征提取","slug":"数据处理与特征工程-特征提取","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"}],"author":"Charles"},{"title":"了解机器学习","slug":"了解机器学习","date":"2021-06-08T12:11:51.000Z","updated":"2021-06-09T03:29:19.182Z","comments":true,"path":"2021/06/08/了解机器学习/","link":"","permalink":"http://example.com/2021/06/08/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"人工智能概述人工智能概述 达特茅斯会议-人工智能的起点 机器学习是人工智能的一个实现途径 深度学习是机器学习的一个方法发展而来机器学习、深度学习能做些什么 传统预测 图像识别 自然语言处理 什么是机器学习机器学习定义机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测 解释类似于人 机器学习数据集结构：特征值+目标值 机器学习算法分类监督学习 目标值：类别 —— 分类问题 具体算法：k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归 目标值：连续性数据 —— 回归问题 具体算法：线性回归、岭回归 无监督学习 目标值：无 具体算法：k-means 练习 1.预测明天的气温是多少度？ 回归 2.预测明天是阴、晴还是雨？ 分类 3.人脸年龄预测？ 分类（老小）/回归（具体年龄） 4.人脸识别？ 分类 机器学习开发流程 获取数据 数据处理 特征工程 建立模型（算法训练） 模型评估 应用 学习框架和资料介绍 算法是核心、数据与计算是基础 找准定位 大部分复杂模型的算法设计都是算法工程师在做，而我们做的是： 分析很多数据 分析具体的业务 应用常见的算法 特征工程、调参、优化 怎么做？ 入门 实战类书记 机器学习（西瓜书） - 周志华统计学习方法 - 李航深度学习（花书）","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"了解机器学习","slug":"了解机器学习","permalink":"http://example.com/tags/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"author":"Charles"},{"title":"hexo博客搭建与优化","slug":"hexo博客搭建","date":"2021-01-14T07:32:42.000Z","updated":"2021-06-09T03:29:50.720Z","comments":true,"path":"2021/01/14/hexo博客搭建/","link":"","permalink":"http://example.com/2021/01/14/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","excerpt":"","text":"安装需要的软件软件安装 我们需要安装nodejs、git bash、npm、Hexo其中我们只需要下载前两个就行了 Nodejs下载地址 Git下载地址 Git安装参考 Git配置参考 最新版的Nodejs中包含了npm，所以我们不需要额外的安装了 下载完之后无脑点下一步就可以了,哈哈是不是很简单呢？ 我们打开Git Bash输入下面命令来检测安装是否成功 node -v和npm -v如果没有问题的话，应该是这样字的。 我们启动cmd，输入以下两条命令，成功后之后通过npm全局安装的包都会存放到node_global文件夹(这个文件夹是我自己创建的,你也可以创建在不同位置)下，后续查找包较方便。 123npm config set prefix &quot;D:\\Program Files\\nodejs\\node_global&quot;npm config set cache &quot;D:\\Program Files\\nodejs\\node_cache&quot; 这里的路径要记住，接下来可能我们在配置环境变量的时候，还将会用到 检测没问题之后，我们安装最后一个东西hexo打开Git Bash输入npm install -g hexo安装完之后的显示信息如下所示: 但是如果你会发现Hexo无法使用,我们还需要配置环境变量 配置环境变量这步，可能会比较的难，你需要跟着我做。 我的电脑右击属性-&gt;点高级系统配置-&gt;点环境变量-&gt;在最上边一栏双击Path-&gt;点击新建-&gt;然后输入你node_global的路径 步骤如图所示: 开始秒建博客准备工作做了这么多了，现在我们终于要开始搭建自己的博客了,进入一个你博客存放的位置,然后在命令行中输入hexo init,这是博客的初始化操作,紧接着我们休息片刻喝口水.现在初始化完毕了，我们首先看看我们的博客长什么样子吧!我们在命令行中输入hexo s(s是start的意思),然后我们打开浏览器输入网址localhost:4000我们就可以看到自己的博客了，博客如下图所示:这时候大家可能会说，这是什么垃圾博客，白给我都不要，走了走了，算了算了。大哥们，咱们先简单配置一下并说说Hexo的基本用法，然后就美化一下，相信我，最后不会很垃圾的. 简单配置一下博客博客的配置文件是你博客的根目录的_config.yml文件然后我们打开文件,进行基本的配置 12345678# Sitetitle: CharlesBlog # 这里写博客的名字subtitle: # 这里写博客的副标题description: &#39;&#39; # 关于你博客的描述keywords:author: Charles # 这里写博客的作者language: zh-CN # 博客语言timezone: &#39;&#39; 简单配置完毕，接来下我们学一下Hexo的基本命令 Hexo基本命令 命令 作用 Hexo init 初始化博客 Hexo s 运行博客 Hexo n title 创建一篇新的文章，文章标题是title Hexo c 清理文件 Hexo g 生成静态文件 Hexo d 程序部署博客（需要插件） 安装主题并简单配置butterfly主题 Hexo官网主题 主题的预览图: 接下来执行git clone https://github.com/jerryc127/hexo-theme-butterfly themes/butterfly进行安装,这里我们先让他安装着，我们打开我们的配置文件找到这一行theme: landspace然后将landspace替换成我们的主题也就是butterfly 此时运行博客 是运行不了的，因为我们少了一个插件，我们通过命令npm install hexo-renderer-pug hexo-renderer-stylus来安装这个插件最终完美运行. 为了以后升级方便，这里不推荐直接对主题的配置文件进行修改，而是复制配置文件进行修改。个人推荐把主題的配置文件_config.yml复制到 Hexo 的根目录下命名为_config.butterfly.yml，如果目录不存在那就创建一个。 配置主页大图片安装完博客后我们看到的就是这个大图片你可能会说不好看，接下来我们进行更换这个图片，首先我们先找到一个自己想更换的图片,接下来我们将他放到图床当中去，本人经常用路过图床,然后将我们的图片上传上去，这里会显示一个连接，我们先复制这个链接。 然后找到我们的主题配置文件(路径应该是 博客根目录/_config.butterfly.yml),然后找到default_top_img:这一行将链接替换成你刚才复制的链接即可. 说道这里我们顺便配置一下我们的头像，头像和首页图配置方法是一样的只要在配置文件中找到头像的位置将URL放入即可。 配置主页的导航栏我们可以看到我们的导航栏都是英文，我们可以自己手动修改。 我们打开我们的主题配置文档，路径在哪里我也就不用说了吧，在博客根目录/_config.butterfly.yml(最后一遍了)配置文件开头就是我们的导航栏配置，默认配置如下 12345678910menu: Home: &#x2F; || fa fa-home Archives: &#x2F;archives&#x2F; || fa fa-archive Tags: &#x2F;tags&#x2F; || fa fa-tags Categories: &#x2F;categories&#x2F; || fa fa-folder-open Link: &#x2F;link&#x2F; || fa fa-link About: &#x2F;about&#x2F; || fa fa-heart List||fa fa-list: - Music || &#x2F;music&#x2F; || fa fa-music - Movie || &#x2F;movies&#x2F; || fa fa-film 最终我修改完成后如下所示: 12345678910menu: 首页: &#x2F; || fas fa-home 归档: &#x2F;archives&#x2F; || fas fa-archive 标签: &#x2F;tags&#x2F; || fas fa-tags 分类: &#x2F;categories&#x2F; || fas fa-folder-open 清单||fas fa-list: - Music || &#x2F;music&#x2F; || fas fa-music - Movie || &#x2F;movies&#x2F; || fas fa-video 友情链接: &#x2F;link&#x2F; || fas fa-link 关于: &#x2F;about&#x2F; || fas fa-heart 相信聪明的你，一看就懂了 主页名人名言 我们在主题配置文件中搜索 Never put off till tomorrow what you can do today然后我们将这句话改成我不知道将去何方 但我已在路上最终实现了替换的效果，并且我们还可以去掉上边的一句话 我们还可以自动获取网络上的好句子，我们只需要将source: false换成下面你想选择的样式 source: 1 #调用博天API https://api.btstu.cn/ source: 2 #调用一言API https://hitokoto.cn/ source: 3 #调用一句话API http://yijuzhan.com/ source: 4 #调用今日詩詞API https://www.jinrishici.com/ 这里要注意的是: 在显示的时候，会先实现网络获取的一句话，然后在获取本地设置的话 更多butterfly美化在这哦 部署云端现在我们的博客，感觉已经很漂亮了，接下来我们部署云端让所有人看到我们的博客吧!!! 最后！我们需要额外的一个工具来帮助我们推到仓库上，那就是！那就是！那就是 hexo-deployer-git搞它！ 执行下面的命令，进行安装插件 1npm install hexo-deployer-git --save 使用GitHub部署云端 我们在Github中建立一个仓库，其中仓库名字必须是xxx.github.ioxxx是你的Github名字,过程如图所示 接下来，打开我们的博客配置文件,找到下面的内容 1234deploy: type: git repo: &lt;你的仓库地址&gt; # https:&#x2F;&#x2F;github.com&#x2F;TJ-XiaJiaHao&#x2F;TJ-XiaJiaHao.github.io branch: master 然后写上你刚刚建立仓库的地址 执行下面的命令，进行远程部署到我们的Github的仓库 1234 # 清理垃圾hexo clean# 推送到远端hexo d浏览器访问：https://xxxxx.github.io/ 即可看到效果。(把xxxx替换成的Github名字就可以了)例如我的是 https://ciks111.github.io/ 不要着急，可能会有1-2分钟的延迟 最终终于大工告成了 本文也就到此结束了.","categories":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/categories/hexo/"}],"tags":[{"name":"hexo博客搭建","slug":"hexo博客搭建","permalink":"http://example.com/tags/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}],"author":"Charles"}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/categories/hexo/"}],"tags":[{"name":"特征工程-特征降维","slug":"特征工程-特征降维","permalink":"http://example.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/"},{"name":"特征工程-特征预处理","slug":"特征工程-特征预处理","permalink":"http://example.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/"},{"name":"数据处理与特征工程-特征提取","slug":"数据处理与特征工程-特征提取","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%B8%8E%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"},{"name":"了解机器学习","slug":"了解机器学习","permalink":"http://example.com/tags/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"hexo博客搭建","slug":"hexo博客搭建","permalink":"http://example.com/tags/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"}]}