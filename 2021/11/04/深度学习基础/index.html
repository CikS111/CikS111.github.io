<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>深度学习基础 | CharlesBlog</title><meta name="keywords" content="进入深度学习"><meta name="author" content="Charles"><meta name="copyright" content="Charles"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本节目录如下：  前言 监督学习与无监督学习 神经网络 损失函数 梯度下降前言 人工智能可以归结于一句话：针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来。    接下来就一句一句的分析这句话：  针对特定的任务：  首先我们需要知道的是，人工智能其实就是为了让计算机看起来像人一样智能，为什么这么说呢？举一个人工智能的例子：  我们人可看到一个动物的图片，就">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习基础">
<meta property="og:url" content="http://example.com/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="CharlesBlog">
<meta property="og:description" content="本节目录如下：  前言 监督学习与无监督学习 神经网络 损失函数 梯度下降前言 人工智能可以归结于一句话：针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来。    接下来就一句一句的分析这句话：  针对特定的任务：  首先我们需要知道的是，人工智能其实就是为了让计算机看起来像人一样智能，为什么这么说呢？举一个人工智能的例子：  我们人可看到一个动物的图片，就">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://z3.ax1x.com/2021/11/04/IZiI7q.jpg">
<meta property="article:published_time" content="2021-11-04T02:21:00.000Z">
<meta property="article:modified_time" content="2021-11-04T13:28:02.246Z">
<meta property="article:author" content="Charles">
<meta property="article:tag" content="进入深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://z3.ax1x.com/2021/11/04/IZiI7q.jpg"><link rel="shortcut icon" href="https://s3.ax1x.com/2021/01/14/saM29S.png"><link rel="canonical" href="http://example.com/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习基础',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-11-04 21:28:02'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><link rel="stylesheet" href="APlayer.min.css"><div id="aplayer"></div><script src="https://cdn.jsdelivr.net/gh/radium-bit/res@master/live2d/autoload.js" async></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js" async></script><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://s3.ax1x.com/2021/01/14/saMJk6.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Music"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/Movie"><i class="fa-fw /movies/"></i><span> 1</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://z3.ax1x.com/2021/11/04/IZiI7q.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">CharlesBlog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/Music"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/Movie"><i class="fa-fw /movies/"></i><span> 1</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习基础</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-11-04T02:21:00.000Z" title="发表于 2021-11-04 10:21:00">2021-11-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-11-04T13:28:02.246Z" title="更新于 2021-11-04 21:28:02">2021-11-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习基础"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本节目录如下：</p>
<ul>
<li>前言</li>
<li>监督学习与无监督学习</li>
<li>神经网络</li>
<li>损失函数</li>
<li>梯度下降<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h2><blockquote>
<p>人工智能可以归结于一句话：<strong>针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来。</strong></p>
</blockquote>
</li>
</ul>
<p><strong>接下来就一句一句的分析这句话：</strong></p>
<ul>
<li><strong>针对特定的任务：</strong></li>
</ul>
<p>首先我们需要知道的是，人工智能其实就是为了让计算机看起来像人一样智能，为什么这么说呢？举一个人工智能的例子：</p>
<blockquote>
<p>我们人可看到一个动物的图片，就可以立刻知道这个动物是猫，还是狗。但是计算机却不可以，如果这个计算机可以分出类别，那么这就会使一个具有图像分类功能的人工智能的小例子。</p>
</blockquote>
<p>这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>图像分类</strong></font></font>就是我们所说的特定任务，这就是我们希望写出一个人工智能的程序来做的事情。</p>
<p>还有一些其他的常见的任务：<font style='background:#F6E1E7'><font color="#D83B64"><strong>人脸识别</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>目标检测</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>图像分割</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>自然语言处理</strong></font></font>等等。</p>
<ul>
<li><strong>找出合适的数学表达式</strong></li>
</ul>
<p>学过高等数学并且有计算机思维的人都知道，世界中几乎所有的事情都可以用数学函数来表达出来，我们先不管这个数学表达式是离散还是连续，也不管它的次数多高，反正它都能达到表示特定任务的一种目的。</p>
<p>比如说，针对一个西瓜质量的好坏的预测任务，可以设出一下的表达式：<br><a target="_blank" rel="noopener" href="https://imgtu.com/i/IZQiCj"><img src="https://z3.ax1x.com/2021/11/04/IZQiCj.png" alt="IZQiCj.png"></a></p>
<p><strong>解释如下：</strong></p>
<blockquote>
<p>1、<font style='background:#F6E1E7'><font color="#D83B64"><strong>x1,x2,x3</strong></font></font>可以看作判断西瓜好坏的判断依据，比如说可以是：瓜皮纹路，敲击声音，瓜皮颜色等等。<br><br>2、<font style='background:#F6E1E7'><font color="#D83B64"><strong>a,b,c,d</strong></font></font>就是这个表达式的系数，一旦数学表达式定下来了，那么接下来需要做的事情就是找出合适的系数，使得这个表达式可以很好的判断出西瓜质量的好坏。</p>
</blockquote>
<p>所以，针对上文提到的特定任务，都可以用数学表达式表示出来，当然，我们会尽可能找出简单、高效的表达式。</p>
<ul>
<li><strong>一直优化这个表达式：</strong></li>
</ul>
<p>上边引出表达式之后，会发现当表达式确定下来之后，就要<strong>寻找合适的系数</strong>了,寻找系数的过程就被称为<strong>训练网络的过程</strong>。</p>
<p>我们优化表达式的重要思想是：<strong>一直调整系数值，使得预测出来的数据与真实数据之间的差距尽可能的最小。</strong></p>
<p>比如：假设<strong>预测的数据</strong>是<font style='background:#F6E1E7'><font color="#D83B64"><strong>f1(x)</strong></font></font>，真实数据是<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>，我们通过一直改变系数的值，来找出可以使得预测数据与真实数据之间距离最小的一组，最小的一组数据就是我们需要的系数。</p>
<p>其中，距离计算公式可以是如下的表达式：<br><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/IZ1Wgs"><img src="https://z3.ax1x.com/2021/11/04/IZ1Wgs.png" alt="IZ1Wgs.png"></a></p>
<p>通过这个表达式，得到的<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>值就是真实值与预测值之间的距离。</p>
<p>然后，接下来的优化就是针对这个<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>表达式来进行的，目的就是让<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>的值达到最小。</p>
<p>因为<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>值达到最小的时候，就意味着我们的预测值与真实值距离很相近，预测越准确。</p>
<blockquote>
<p>这里值得一提的是，这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>表达式的优化过程，其实就是将<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>公式对函数<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>的系数的求导。<br><br>所以当<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>最小的时候，就意味着此时的系数最合适。<br><br>具体的细节往下看。</p>
</blockquote>
<ul>
<li><strong>用优化好的表达式预测未来：</strong><br>经过上边的优化，此时函数会得到一个相对好一点的系数，然后就可以使用这个函数来预测未来的事情了。</li>
</ul>
<p>这就是达到了人工智能的目的了。</p>
<p><strong>所以，下边我们就要仔细讨论，数学表达式的构建，距离函数的构建，距离的优化。</strong></p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a><strong>神经网络</strong></h2><blockquote>
<p>神经网络的英文是：neural network（简称NN）。</p>
</blockquote>
<p>神经网络其实就是变形的数学表达式，它通过拼装基础组件（神经元）来<strong>模拟出数学表达式</strong>。</p>
<h3 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a><strong>什么是神经网络</strong></h3><p>一说神经网络，大家首先想到的就是神经元，其实没错，神经网络这个名词就是从神经元这里演变过来的。所以我们做一下类比。</p>
<h4 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h4><p><a target="_blank" rel="noopener" href="https://imgtu.com/i/Ie2CSH"><img src="https://z3.ax1x.com/2021/11/04/Ie2CSH.png" alt="Ie2CSH.png"></a></p>
<p>如图所示，这个图就是我们人体的神经元的大图。</p>
<p>通常我们身体的<font style='background:#F6E1E7'><font color="#D83B64"><strong>A</strong></font></font>部位发出的命令，要指挥<font style='background:#F6E1E7'><font color="#D83B64"><strong>B</strong></font></font>部位响应，就要通过<font style='background:#F6E1E7'><font color="#D83B64"><strong>A</strong></font></font>向<font style='background:#F6E1E7'><font color="#D83B64"><strong>B</strong></font></font>发出信号。这个信号的强弱影响着<font style='background:#F6E1E7'><font color="#D83B64"><strong>B</strong></font></font>反应的强弱。</p>
<p>所以，这就是神经网络的构思所在：</p>
<p><strong>构建出一个类似于神经元的结构，上一个节点的输入（A处的控制） 以及权重（信号的强弱）共同决定下一个节点的输出（B处的反应）。</strong></p>
<blockquote>
<p>这句话，现在看不懂没关系，有个印象就好，继续往下看吧。</p>
</blockquote>
<h4 id="神经网络-1"><a href="#神经网络-1" class="headerlink" title="神经网络"></a>神经网络</h4><p><a target="_blank" rel="noopener" href="https://imgtu.com/i/Ie2d1J"><img src="https://z3.ax1x.com/2021/11/04/Ie2d1J.png" alt="Ie2d1J.png"></a></p>
<p>如图所示就是一个最简单的神经网络结构，这个结构的数学表达式是：<br><a target="_blank" rel="noopener" href="https://imgtu.com/i/Ie2Dn1"><img src="https://z3.ax1x.com/2021/11/04/Ie2Dn1.png" alt="Ie2Dn1.png"></a></p>
<p>图中的圆圈我们就把他类比于神经元，图中的各个结构解释如下：</p>
<ul>
<li>其中 <font style='background:#F6E1E7'><font color="#D83B64"><strong>X1</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>X2</strong></font></font> 就是这个神经网络的<strong>输入</strong>，他相当于就是人体大脑发出的控制命令。</li>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>W1</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>W2</strong></font></font> 就是<strong>权重</strong>，他是用来控制不同输入信号占比大小的数据，比如：想让控制X1作用明显一点，那么对应的<font style='background:#F6E1E7'><font color="#D83B64"><strong>W1</strong></font></font>就大一点。</li>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>就是<strong>输出</strong>，他就是输入数据与权重作用之后的最终结果，在神经元中也就是最终对身体某个部位的控制信号。</li>
</ul>
<h3 id="神经网络的数学原理"><a href="#神经网络的数学原理" class="headerlink" title="神经网络的数学原理"></a><strong>神经网络的数学原理</strong></h3><p>神经网络的数学原理非常简单，简单总结下来就是一句话：<strong>不同的输入</strong>作用于<strong>各自的权重</strong>之后<strong>的和</strong>即为我们需要的结果。</p>
<blockquote>
<p>其实就可以大致理解为我们的函数：<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x) = a<em>x1 + b</em>x2</strong></font></font> 一样，所谓的权重就是我们方程的系数。</p>
</blockquote>
<p>细心的人观察上边的公式就会发现，<strong>一个神经元节点</strong>就可以<strong>归结于一个运算式子</strong>。所以我们这里就来针对上图，分析分析含有一个神经元节点的公式。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/IeRM4O"><img src="https://z3.ax1x.com/2021/11/04/IeRM4O.png" alt="IeRM4O.png"></a></p>
<p>从图中可以看得出来，最终的输出结果<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>是由 <font style='background:#F6E1E7'><font color="#D83B64"><strong>输入（X）</strong></font></font> 以及 <font style='background:#F6E1E7'><font color="#D83B64"><strong>权重（W）</strong></font></font> 共同决定的。</p>
<p>他们最终的计算结果 <font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>其实说白了就是一个计算公式：<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y = X1<em>W1 + X2</em>W2​</strong></font></font> ，这个公式的含义大家应该都明白，<strong>给不同的输入 分配不同的权重 ，从而得到想要的结果</strong>。</p>
<p>这就是神经网络中一个神经元的数学原理，当把神经元的个数增多之后，原理以此类推，只不过是要增加权重<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font>以及输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>X</strong></font></font>的个数而已。</p>
<p><strong>下边就可以看作是一个，含有两层的神经网络结构。</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImCAud"><img src="https://z3.ax1x.com/2021/11/04/ImCAud.md.png" alt="ImCAud.md.png"></a></p>
<ul>
<li>第一层节点： <font style='background:#F6E1E7'><font color="#D83B64"><strong>11</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>12</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>13</strong></font></font> 。第二层节点： <font style='background:#F6E1E7'><font color="#D83B64"><strong>21</strong></font></font> 。</li>
<li>输入： <font style='background:#F6E1E7'><font color="#D83B64"><strong>X1</strong></font></font> ，<font style='background:#F6E1E7'><font color="#D83B64"><strong>X2</strong></font></font> 。 输出 ：<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font> 。<br><br>遇是，根据公式：<strong>输出</strong>等于<strong>输入</strong>作用于<strong>权重</strong>，得出以下推导：</li>
<li>输入：<font style='background:#F6E1E7'><font color="#D83B64"><strong>X1</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>X2</strong></font></font>.</li>
<li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>11</strong></font></font>的值：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImPEzF"><img src="https://z3.ax1x.com/2021/11/04/ImPEzF.png" alt="ImPEzF.png"></a></li>
<li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>12</strong></font></font>的值：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImP3RO"><img src="https://z3.ax1x.com/2021/11/04/ImP3RO.png" alt="ImP3RO.png"></a></li>
<li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>13</strong></font></font>的值：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImPYsH"><img src="https://z3.ax1x.com/2021/11/04/ImPYsH.png" alt="ImPYsH.png"></a></li>
<li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>21</strong></font></font>的值就是最终输出<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImikTI"><img src="https://z3.ax1x.com/2021/11/04/ImikTI.png" alt="ImikTI.png"></a></li>
</ul>
<p><strong>所以，最终的整合式子为：</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImFXRK"><img src="https://z3.ax1x.com/2021/11/04/ImFXRK.png" alt="ImFXRK.png"></a></p>
<p><strong>于是，我们可以发现，类似于这样的堆叠方式，我们可以组合成很多的数学函数。</strong></p>
<blockquote>
<p>这就是神经网络，他的目的在于将数学公式堆砌出来，至于为什么要这样堆砌，是因为<strong>这样堆砌计算机计算比较方便</strong>呗。</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>到目前为止你已经知道了神经网络的由来，并且知道神经网络与数学公式之间的关系。</p>
<p><strong>此时你需要明确的知识点是：</strong></p>
<ul>
<li><strong>人工智能就是使用已有的数据，拟合出一个可以用来预测未来的公式。</strong></li>
<li><strong>这个公式的系数需要一直调整，从而找出一组最为合适，正确率较高的系数。</strong></li>
<li><strong>因为系数的寻找需要大量的计算，所以需要将这个公式用神经网络表示出来的，因为在计算机中这样表示的时候计算最为方便。</strong></li>
</ul>
<h2 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a><strong>监督学习与无监督学习</strong></h2><blockquote>
<p>这个知识点比较简单，就一些单纯的概念。</p>
</blockquote>
<p><strong>监督学习：</strong> 就是我们收集到的数据是有标签的。</p>
<blockquote>
<p>就是说，我们收集到的数据是已经分好类的。<br><br>比如说：当前当前有一批样本数据，</p>
</blockquote>
<ul>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>x1, x2, x6, x9, x13</strong></font></font>属于类别<font style='background:#F6E1E7'><font color="#D83B64"><strong>y1</strong></font></font>类。</li>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>x3, x4, x5, x8, x11</strong></font></font>属于类别<font style='background:#F6E1E7'><font color="#D83B64"><strong>y2</strong></font></font>类。</li>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>x7, x10, x12</strong></font></font>属于类别<font style='background:#F6E1E7'><font color="#D83B64"><strong>y3</strong></font></font>类。</li>
</ul>
<p>然后接下来我们使用这些数据的时候，就可以使用已有标签的数据，去拟合出曲线，用以预测未来。</p>
<p><strong>无监督学习：</strong> 我们收集到的数据是无标签的。</p>
<blockquote>
<p>就是说，收集到的数据并没有固定的类别，我们需要做的事情就是挖掘数据内部的联系，给他们聚类，找出类别。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImE6VH"><img src="https://z3.ax1x.com/2021/11/04/ImE6VH.png" alt="ImE6VH.png"></a></p>
<p>如图所示，挖掘出数据内部的联系，让他自动归类。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h2><blockquote>
<p>上边解释过了，损失函数的作用就是计算 <strong>真实值</strong> 与 <strong>预测值</strong> 之间距离的 （距离其实可以简单理解为两个数据之间的差距）。</p>
</blockquote>
<p>这里介绍一些常见的几种损失函数，以供大家入门使用。</p>
<h3 id="一些前提"><a href="#一些前提" class="headerlink" title="一些前提"></a><strong>一些前提</strong></h3><blockquote>
<p>这里给定一些大前提，下边的几种损失函数通用的那种。</p>
</blockquote>
<ul>
<li><strong>真实值：</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font> ，他就是针对某一组输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>的真实标签。</li>
<li><strong>预测值：</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>，他就是针对输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>的预测标签。</li>
<li><strong>样本数：</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font>，他就是我们每次输入多少样本进行计算，比如：某一次输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>5</strong></font></font>组<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>，得到<font style='background:#F6E1E7'><font color="#D83B64"><strong>5</strong></font></font>个预测结果，这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>m=5</strong></font></font>.</li>
</ul>
<h3 id="绝对值损失函数"><a href="#绝对值损失函数" class="headerlink" title="绝对值损失函数"></a><strong>绝对值损失函数</strong></h3><blockquote>
<p>其实就是简单的计算 真实值 与 预测值 之间的绝对值距离而已。</p>
</blockquote>
<p><strong>公式：</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImVOTH"><img src="https://z3.ax1x.com/2021/11/04/ImVOTH.png" alt="ImVOTH.png"></a></p>
<p><strong>解释：</strong></p>
<ul>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>J(y,f(x))</strong></font></font> 的意思就是，这个损失函数的参数是：真是标签<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font> 与 预测数据<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>  。</li>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>J(w,b)</strong></font></font> 的意思是，这个损失函数的目的是优化参数 <font style='background:#F6E1E7'><font color="#D83B64"><strong>w</strong></font></font> 与 <font style='background:#F6E1E7'><font color="#D83B64"><strong>b</strong></font></font> 。这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>w</strong></font></font> ，<font style='background:#F6E1E7'><font color="#D83B64"><strong>b</strong></font></font> 其实就是系数的矩阵形式。</li>
<li>后边具体的计算公式就是：输入有<font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font> 个样本，计算出这<font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font> 个样本的距离绝对值和，然后再求均值。</li>
</ul>
<h3 id="均方差损失函数"><a href="#均方差损失函数" class="headerlink" title="均方差损失函数"></a><strong>均方差损失函数</strong></h3><blockquote>
<p>就是将上边式子的绝对值换成平方就好了。</p>
</blockquote>
<p><strong>公式：</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/Imm9eS"><img src="https://z3.ax1x.com/2021/11/04/Imm9eS.png" alt="Imm9eS.png"></a></p>
<p><strong>解释：</strong></p>
<ul>
<li>这里只是将绝对值换成了平方，除以<font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font>换成了除以<font style='background:#F6E1E7'><font color="#D83B64"><strong>2m</strong></font></font>。</li>
</ul>
<h3 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a><strong>交叉熵损失函数</strong></h3><blockquote>
<p>这个就比较麻烦了，交叉熵损失函数一般用于解决分类问题。</p>
</blockquote>
<p><strong>标签：</strong></p>
<p>在通常的分类问题中，标签<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>的取值一般只有 <font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font> 或 <font style='background:#F6E1E7'><font color="#D83B64"><strong>1</strong></font></font> 。</p>
<blockquote>
<p>1 表示是当前类别， 0 表示不是当前类别。</p>
</blockquote>
<p><strong>公式：</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/Imnp11"><img src="https://z3.ax1x.com/2021/11/04/Imnp11.md.png" alt="Imnp11.md.png"></a></p>
<p><strong>解释：</strong></p>
<ul>
<li><p>上边说了，<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>与 <font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font> 都只能取 <font style='background:#F6E1E7'><font color="#D83B64"><strong>1</strong></font></font>与 <font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font>f 中的一种可能性。所以，上述公式的效果就是：</p>
</li>
<li><p><strong>如果 y与 f(x) 相同，则 J = 0.</strong></p>
</li>
</ul>
<blockquote>
<p>你带入<font style='background:#F6E1E7'><font color="#D83B64"><strong>y=1 , f(x)=1</strong></font></font> 试试就知道了。</p>
</blockquote>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>到这里你已经学习了三种常见的损失函数。</p>
<p><strong>此时你应该有一个明确的知识点就是：</strong></p>
<ul>
<li><strong>损失函数是用来计算真实值与预测值之间距离的。</strong></li>
<li><strong>当损失函数的值越小就代表着真实值与预测值之间的距离就越小，也就意味着预测的越准。</strong></li>
</ul>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a><strong>梯度下降</strong></h2><blockquote>
<p>好了好了，上边过完理论知识，这里来一个真真正正的数学内容了，其实不难，看我慢慢分析。</p>
</blockquote>
<ul>
<li>上边我们提到对数学函数优化的时候，只是介绍了理论的知识。</li>
</ul>
<blockquote>
<p>我们知道了损失函数就是衡量预测值与真实值之间距离的公式。<br><br>并且知道，损失函数的值越小，真实值和预测值之间的距离越小，也即：预测的越准。</p>
</blockquote>
<ul>
<li>但是并没有带着大家深入探究如何优化。</li>
</ul>
<blockquote>
<p>也就是没有告诉大家怎么使得损失函数的值越来越小。</p>
</blockquote>
<p><strong>其实，这里使用的数学知识就是 ：求偏导</strong></p>
<h3 id="数学例子"><a href="#数学例子" class="headerlink" title="数学例子"></a><strong>数学例子</strong></h3><blockquote>
<p>这里以一个简单的数学例子来引入梯度下降的内容。</p>
</blockquote>
<ul>
<li><strong>场景引入</strong></li>
</ul>
<blockquote>
<p>在数学课中我们经常做的一个题型就是：已知一个函数<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>的表达式，如何求出这个式子的最小值点。</p>
</blockquote>
<p>在数学题中我们经常用的方法就是：将函数<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>对<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>求导，然后令导数式子为0，求出此时的x的值，即为最小值点的位置。</p>
<ul>
<li><strong>具体例子</strong></li>
</ul>
<blockquote>
<p>求函数<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImuwRA"><img src="https://z3.ax1x.com/2021/11/04/ImuwRA.png" alt="ImuwRA.png"></a>的最小值点，并且求出最小值。</p>
</blockquote>
<p><strong>对函数求导</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImugIg"><img src="https://z3.ax1x.com/2021/11/04/ImugIg.png" alt="ImugIg.png"></a></p>
<p><strong>令导函数为0，求出此时的x</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImuWGj"><img src="https://z3.ax1x.com/2021/11/04/ImuWGj.png" alt="ImuWGj.png"></a></p>
<p>此时，<font style='background:#F6E1E7'><font color="#D83B64"><strong>x=3</strong></font></font>即为函数 <font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>的最小值点，带入原方程 <font style='background:#F6E1E7'><font color="#D83B64"><strong>f(3)= 2<em>9-12</em>3+20 = 2</strong></font></font>.</p>
<blockquote>
<p>这个解题过程，想必大家都很熟悉吧。</p>
</blockquote>
<p><strong>下边就分析一下这个过程的数学原理了</strong></p>
<h3 id="数学例子原理"><a href="#数学例子原理" class="headerlink" title="数学例子原理"></a><strong>数学例子原理</strong></h3><blockquote>
<p>梯度就是导数。</p>
</blockquote>
<p>针对上边提到的方程的最小值求解，其实就是求出其梯度（导数）为0的位置，就是其最低点的位置。具体看下图：</p>
<ul>
<li>方程<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImuXW9"><img src="https://z3.ax1x.com/2021/11/04/ImuXW9.png" alt="ImuXW9.png"></a>图像如下：<br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImuxQ1"><img src="https://z3.ax1x.com/2021/11/04/ImuxQ1.png" alt="ImuxQ1.png"></a></li>
</ul>
<blockquote>
<p>从图中可以看出，方程在不同位置的导数方向是不同的，只有在最低点的位置，导数为<font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font>，所以可以用导数为<font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font>的位置求出最低点。</p>
</blockquote>
<p><strong>上边举的例子是一个比较简单的例子，方程中只有一个未知数，但是在真实情况中，往往一个方程有很多未知数。</strong></p>
<ul>
<li>比如：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImKFFe"><img src="https://z3.ax1x.com/2021/11/04/ImKFFe.png" alt="ImKFFe.png"></a></li>
</ul>
<blockquote>
<p>此时需要做的事情就是针对每一个变量求偏导，<strong>求出该方程针对每个变量的梯度方向</strong> （梯度方向就是数据变小的方向）。</p>
</blockquote>
<p><strong>于是，在方程的每个点上，都有多个梯度方向，最终将这多个方向合并，形成这个点的最终梯度方向 （数据变小的方向）</strong><br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImKZQI"><img src="https://z3.ax1x.com/2021/11/04/ImKZQI.png" alt="ImKZQI.png"></a></p>
<blockquote>
<p>如图，方程有两个变量<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>,<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>，于是在A点针对两个变量求偏导就可以得到各自的梯度方向（两个红色箭头的方向）。<br><br>然后，将两个梯度进行合并，得到最终的梯度方向<font style='background:#F6E1E7'><font color="#D83B64"><strong>Z</strong></font></font> 。<strong>Z方向就是方程在A点数据变小的方向了。</strong></p>
</blockquote>
<h3 id="完整例子"><a href="#完整例子" class="headerlink" title="完整例子"></a><strong>完整例子</strong></h3><blockquote>
<p>上边讲完原理，这里就举出一个例子，带着大家走一遍梯度下降找最小值的过程。</p>
</blockquote>
<p>假设此时的方程已知，并且根据方程绘制出的图像如下。<br><a target="_blank" rel="noopener" href="https://imgtu.com/i/ImKtO0"><img src="https://z3.ax1x.com/2021/11/04/ImKtO0.png" alt="ImKtO0.png"></a></p>
<ul>
<li>刚开始我们位于A点：</li>
</ul>
<blockquote>
<p>1、在A点处针对方程的各个变量求出偏导，于是便可以得到方程针对各个方向的梯度方向。<br><br>2、将A点处各个方向的梯度方向进行合并，形成最终的梯度方向。<br><br>3、最终的梯度方向就是AB方向。<br><br>4、于是向着AB方向走出一段距离，走到了B点。</p>
</blockquote>
<ul>
<li>到达B点： （思路同上）</li>
</ul>
<blockquote>
<p>1、求出B点处各个方向的梯度方向，然后合并所有梯度方向，得到最终的B点处梯度方向 BC。<br><br>2、于是沿着BC方向，走出一段距离，到达C点。</p>
</blockquote>
<ul>
<li>…重复上述过程：</li>
</ul>
<blockquote>
<p>到达某个点之后，求出各方向的偏导数，然后合并得到最终的梯度方向。<br><br>然后沿着合并后的梯度方向走出一段距离到达下一个点。<br><br>然后在一直重复……</p>
</blockquote>
<ul>
<li>到达K点：</li>
</ul>
<blockquote>
<p>K点就是最终的点，这就是优化得到的最重点。</p>
</blockquote>
<p><strong>这就是整个找最小点的可视化过程，但是其中提到更新的数学细节并没有提到，所以下边提一下用到的数学更新公式吧</strong></p>
<h3 id="更新公式"><a href="#更新公式" class="headerlink" title="更新公式"></a><strong>更新公式</strong></h3><blockquote>
<p>一般我们梯度下降更新的数据只有函数的系数，然后函数的系数可以分为两类：权重（W）+ 偏差（b）<br><br>所以，更新的时候也就针对这两个参数就好了。</p>
</blockquote>
<p><strong>变量定义：</strong></p>
<ul>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>w</strong></font></font> ： 方程的权重。 （可以简单理解为方程变量前面的系数）</li>
<li><font style='background:#F6E1E7'><font color="#D83B64"><strong>b</strong></font></font>  ：方程的偏差。 （可以简单理解为方程中的常数）</li>
</ul>
<blockquote>
<p>比如：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImKxhQ"><img src="https://z3.ax1x.com/2021/11/04/ImKxhQ.png" alt="ImKxhQ.png"></a>中，<font style='background:#F6E1E7'><font color="#D83B64"><strong>2 , 1</strong></font></font> 就是权重，<font style='background:#F6E1E7'><font color="#D83B64"><strong>3</strong></font></font>就是偏差。</p>
</blockquote>
<p><strong>公式：</strong></p>
<ul>
<li>更新权重<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> ：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImMn39"><img src="https://z3.ax1x.com/2021/11/04/ImMn39.png" alt="ImMn39.png"></a></li>
</ul>
<blockquote>
<p>原始点的权重是<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImMjDx"><img src="https://z3.ax1x.com/2021/11/04/ImMjDx.png" alt="ImMjDx.png"></a> ，原始点此时针对<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> 的梯度方向是<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImQp5D"><img src="https://z3.ax1x.com/2021/11/04/ImQp5D.png" alt="ImQp5D.png"></a>.<br><br><font style='background:#F6E1E7'><font color="#D83B64"><strong>α</strong></font></font>  就是一段距离长度（它就是我们上文一直提到的走一段距离）。<br><br>所以<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImQVqP"><img src="https://z3.ax1x.com/2021/11/04/ImQVqP.png" alt="ImQVqP.png"></a>  表达的含义就是沿着<font style='background:#F6E1E7'><font color="#D83B64">** W**</font></font> 的梯度走一段长度为 <font style='background:#F6E1E7'><font color="#D83B64"><strong>α</strong></font></font> 的距离。<br><br>然后 <strong>新的</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> 就是 <strong>旧的</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> 减去那一段<strong>方向长度</strong>。</p>
</blockquote>
<ul>
<li>更新偏差：<a target="_blank" rel="noopener" href="https://imgtu.com/i/ImllFO"><img src="https://z3.ax1x.com/2021/11/04/ImllFO.png" alt="ImllFO.png"></a></li>
</ul>
<blockquote>
<p>原理同<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font>.</p>
</blockquote>
<p><strong>这就是更新参数的整个梯度下降过程了。</strong></p>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>到目前为止，基础的人工智能知识已经基本讲完了，这个时候我们再来仔细品味这句话。</p>
<p><strong>针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来。</strong></p>
<p>或许你就会有不一样的体会了。</p>
<p><font face="微软雅黑" size=0.3><em>参考文献：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/xiaoxiaojiea/p/14637326.html">https://www.cnblogs.com/xiaoxiaojiea/p/14637326.html</a></em></font></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Charles</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/">http://example.com/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">CharlesBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%BF%9B%E5%85%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">进入深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://z3.ax1x.com/2021/11/04/IZiI7q.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/09/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/"><img class="next-cover" src="https://z3.ax1x.com/2021/09/23/40KHzj.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">特征工程-特征降维</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://s3.ax1x.com/2021/01/14/saMJk6.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Charles</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ccikss519"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/CikS111/CikS111.github.io" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">正式进军机器学习</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">2.</span> <span class="toc-text">神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">2.1.</span> <span class="toc-text">什么是神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E5%85%83"><span class="toc-number">2.1.1.</span> <span class="toc-text">神经元</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-1"><span class="toc-number">2.1.2.</span> <span class="toc-text">神经网络</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">神经网络的数学原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.</span> <span class="toc-text">监督学习与无监督学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.</span> <span class="toc-text">损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%89%8D%E6%8F%90"><span class="toc-number">4.1.</span> <span class="toc-text">一些前提</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9D%E5%AF%B9%E5%80%BC%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.2.</span> <span class="toc-text">绝对值损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.3.</span> <span class="toc-text">均方差损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.4.</span> <span class="toc-text">交叉熵损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-number">4.5.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">5.</span> <span class="toc-text">梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E4%BE%8B%E5%AD%90"><span class="toc-number">5.1.</span> <span class="toc-text">数学例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E4%BE%8B%E5%AD%90%E5%8E%9F%E7%90%86"><span class="toc-number">5.2.</span> <span class="toc-text">数学例子原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BE%8B%E5%AD%90"><span class="toc-number">5.3.</span> <span class="toc-text">完整例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%85%AC%E5%BC%8F"><span class="toc-number">5.4.</span> <span class="toc-text">更新公式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-2"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="深度学习基础"><img src="https://z3.ax1x.com/2021/11/04/IZiI7q.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习基础"/></a><div class="content"><a class="title" href="/2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" title="深度学习基础">深度学习基础</a><time datetime="2021-11-04T02:21:00.000Z" title="发表于 2021-11-04 10:21:00">2021-11-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/" title="特征工程-特征降维"><img src="https://z3.ax1x.com/2021/09/23/40KHzj.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="特征工程-特征降维"/></a><div class="content"><a class="title" href="/2021/09/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/" title="特征工程-特征降维">特征工程-特征降维</a><time datetime="2021-09-23T13:52:00.000Z" title="发表于 2021-09-23 21:52:00">2021-09-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/09/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/" title="特征工程-特征预处理"><img src="https://z3.ax1x.com/2021/09/20/4Ju1mj.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="特征工程-特征预处理"/></a><div class="content"><a class="title" href="/2021/09/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/" title="特征工程-特征预处理">特征工程-特征预处理</a><time datetime="2021-09-20T13:12:00.000Z" title="发表于 2021-09-20 21:12:00">2021-09-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/09/%E8%BF%9B%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="数据处理与特征工程-特征提取"><img src="https://z3.ax1x.com/2021/06/09/2ys4hD.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据处理与特征工程-特征提取"/></a><div class="content"><a class="title" href="/2021/06/09/%E8%BF%9B%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="数据处理与特征工程-特征提取">数据处理与特征工程-特征提取</a><time datetime="2021-06-09T03:46:51.000Z" title="发表于 2021-06-09 11:46:51">2021-06-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/08/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="了解机器学习"><img src="https://z3.ax1x.com/2021/06/08/2sRuqA.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="了解机器学习"/></a><div class="content"><a class="title" href="/2021/06/08/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="了解机器学习">了解机器学习</a><time datetime="2021-06-08T12:11:51.000Z" title="发表于 2021-06-08 20:11:51">2021-06-08</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Charles</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = ture;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>