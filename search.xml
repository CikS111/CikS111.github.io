<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习基础</title>
      <link href="2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
      <url>2021/11/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本节目录如下：</p><ul><li>前言</li><li>监督学习与无监督学习</li><li>神经网络</li><li>损失函数</li><li>梯度下降<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h2><blockquote><p>人工智能可以归结于一句话：<strong>针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来。</strong></p></blockquote></li></ul><p><strong>接下来就一句一句的分析这句话：</strong></p><ul><li><strong>针对特定的任务：</strong></li></ul><p>首先我们需要知道的是，人工智能其实就是为了让计算机看起来像人一样智能，为什么这么说呢？举一个人工智能的例子：</p><blockquote><p>我们人可看到一个动物的图片，就可以立刻知道这个动物是猫，还是狗。但是计算机却不可以，如果这个计算机可以分出类别，那么这就会使一个具有图像分类功能的人工智能的小例子。</p></blockquote><p>这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>图像分类</strong></font></font>就是我们所说的特定任务，这就是我们希望写出一个人工智能的程序来做的事情。</p><p>还有一些其他的常见的任务：<font style='background:#F6E1E7'><font color="#D83B64"><strong>人脸识别</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>目标检测</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>图像分割</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>自然语言处理</strong></font></font>等等。</p><ul><li><strong>找出合适的数学表达式</strong></li></ul><p>学过高等数学并且有计算机思维的人都知道，世界中几乎所有的事情都可以用数学函数来表达出来，我们先不管这个数学表达式是离散还是连续，也不管它的次数多高，反正它都能达到表示特定任务的一种目的。</p><p>比如说，针对一个西瓜质量的好坏的预测任务，可以设出一下的表达式：<br><a href="https://imgtu.com/i/IZQiCj"><img src="https://z3.ax1x.com/2021/11/04/IZQiCj.png" alt="IZQiCj.png"></a></p><p><strong>解释如下：</strong></p><blockquote><p>1、<font style='background:#F6E1E7'><font color="#D83B64"><strong>x1,x2,x3</strong></font></font>可以看作判断西瓜好坏的判断依据，比如说可以是：瓜皮纹路，敲击声音，瓜皮颜色等等。<br><br>2、<font style='background:#F6E1E7'><font color="#D83B64"><strong>a,b,c,d</strong></font></font>就是这个表达式的系数，一旦数学表达式定下来了，那么接下来需要做的事情就是找出合适的系数，使得这个表达式可以很好的判断出西瓜质量的好坏。</p></blockquote><p>所以，针对上文提到的特定任务，都可以用数学表达式表示出来，当然，我们会尽可能找出简单、高效的表达式。</p><ul><li><strong>一直优化这个表达式：</strong></li></ul><p>上边引出表达式之后，会发现当表达式确定下来之后，就要<strong>寻找合适的系数</strong>了,寻找系数的过程就被称为<strong>训练网络的过程</strong>。</p><p>我们优化表达式的重要思想是：<strong>一直调整系数值，使得预测出来的数据与真实数据之间的差距尽可能的最小。</strong></p><p>比如：假设<strong>预测的数据</strong>是<font style='background:#F6E1E7'><font color="#D83B64"><strong>f1(x)</strong></font></font>，真实数据是<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>，我们通过一直改变系数的值，来找出可以使得预测数据与真实数据之间距离最小的一组，最小的一组数据就是我们需要的系数。</p><p>其中，距离计算公式可以是如下的表达式：<br><br><a href="https://imgtu.com/i/IZ1Wgs"><img src="https://z3.ax1x.com/2021/11/04/IZ1Wgs.png" alt="IZ1Wgs.png"></a></p><p>通过这个表达式，得到的<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>值就是真实值与预测值之间的距离。</p><p>然后，接下来的优化就是针对这个<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>表达式来进行的，目的就是让<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>的值达到最小。</p><p>因为<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>值达到最小的时候，就意味着我们的预测值与真实值距离很相近，预测越准确。</p><blockquote><p>这里值得一提的是，这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>表达式的优化过程，其实就是将<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>公式对函数<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>的系数的求导。<br><br>所以当<font style='background:#F6E1E7'><font color="#D83B64"><strong>loss</strong></font></font>最小的时候，就意味着此时的系数最合适。<br><br>具体的细节往下看。</p></blockquote><ul><li><strong>用优化好的表达式预测未来：</strong><br>经过上边的优化，此时函数会得到一个相对好一点的系数，然后就可以使用这个函数来预测未来的事情了。</li></ul><p>这就是达到了人工智能的目的了。</p><p><strong>所以，下边我们就要仔细讨论，数学表达式的构建，距离函数的构建，距离的优化。</strong></p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a><strong>神经网络</strong></h2><blockquote><p>神经网络的英文是：neural network（简称NN）。</p></blockquote><p>神经网络其实就是变形的数学表达式，它通过拼装基础组件（神经元）来<strong>模拟出数学表达式</strong>。</p><h3 id="什么是神经网络"><a href="#什么是神经网络" class="headerlink" title="什么是神经网络"></a><strong>什么是神经网络</strong></h3><p>一说神经网络，大家首先想到的就是神经元，其实没错，神经网络这个名词就是从神经元这里演变过来的。所以我们做一下类比。</p><h4 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h4><p><a href="https://imgtu.com/i/Ie2CSH"><img src="https://z3.ax1x.com/2021/11/04/Ie2CSH.png" alt="Ie2CSH.png"></a></p><p>如图所示，这个图就是我们人体的神经元的大图。</p><p>通常我们身体的<font style='background:#F6E1E7'><font color="#D83B64"><strong>A</strong></font></font>部位发出的命令，要指挥<font style='background:#F6E1E7'><font color="#D83B64"><strong>B</strong></font></font>部位响应，就要通过<font style='background:#F6E1E7'><font color="#D83B64"><strong>A</strong></font></font>向<font style='background:#F6E1E7'><font color="#D83B64"><strong>B</strong></font></font>发出信号。这个信号的强弱影响着<font style='background:#F6E1E7'><font color="#D83B64"><strong>B</strong></font></font>反应的强弱。</p><p>所以，这就是神经网络的构思所在：</p><p><strong>构建出一个类似于神经元的结构，上一个节点的输入（A处的控制） 以及权重（信号的强弱）共同决定下一个节点的输出（B处的反应）。</strong></p><blockquote><p>这句话，现在看不懂没关系，有个印象就好，继续往下看吧。</p></blockquote><h4 id="神经网络-1"><a href="#神经网络-1" class="headerlink" title="神经网络"></a>神经网络</h4><p><a href="https://imgtu.com/i/Ie2d1J"><img src="https://z3.ax1x.com/2021/11/04/Ie2d1J.png" alt="Ie2d1J.png"></a></p><p>如图所示就是一个最简单的神经网络结构，这个结构的数学表达式是：<br><a href="https://imgtu.com/i/Ie2Dn1"><img src="https://z3.ax1x.com/2021/11/04/Ie2Dn1.png" alt="Ie2Dn1.png"></a></p><p>图中的圆圈我们就把他类比于神经元，图中的各个结构解释如下：</p><ul><li>其中 <font style='background:#F6E1E7'><font color="#D83B64"><strong>X1</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>X2</strong></font></font> 就是这个神经网络的<strong>输入</strong>，他相当于就是人体大脑发出的控制命令。</li><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>W1</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>W2</strong></font></font> 就是<strong>权重</strong>，他是用来控制不同输入信号占比大小的数据，比如：想让控制X1作用明显一点，那么对应的<font style='background:#F6E1E7'><font color="#D83B64"><strong>W1</strong></font></font>就大一点。</li><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>就是<strong>输出</strong>，他就是输入数据与权重作用之后的最终结果，在神经元中也就是最终对身体某个部位的控制信号。</li></ul><h3 id="神经网络的数学原理"><a href="#神经网络的数学原理" class="headerlink" title="神经网络的数学原理"></a><strong>神经网络的数学原理</strong></h3><p>神经网络的数学原理非常简单，简单总结下来就是一句话：<strong>不同的输入</strong>作用于<strong>各自的权重</strong>之后<strong>的和</strong>即为我们需要的结果。</p><blockquote><p>其实就可以大致理解为我们的函数：<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x) = a<em>x1 + b</em>x2</strong></font></font> 一样，所谓的权重就是我们方程的系数。</p></blockquote><p>细心的人观察上边的公式就会发现，<strong>一个神经元节点</strong>就可以<strong>归结于一个运算式子</strong>。所以我们这里就来针对上图，分析分析含有一个神经元节点的公式。</p><p><a href="https://imgtu.com/i/IeRM4O"><img src="https://z3.ax1x.com/2021/11/04/IeRM4O.png" alt="IeRM4O.png"></a></p><p>从图中可以看得出来，最终的输出结果<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>是由 <font style='background:#F6E1E7'><font color="#D83B64"><strong>输入（X）</strong></font></font> 以及 <font style='background:#F6E1E7'><font color="#D83B64"><strong>权重（W）</strong></font></font> 共同决定的。</p><p>他们最终的计算结果 <font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>其实说白了就是一个计算公式：<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y = X1<em>W1 + X2</em>W2​</strong></font></font> ，这个公式的含义大家应该都明白，<strong>给不同的输入 分配不同的权重 ，从而得到想要的结果</strong>。</p><p>这就是神经网络中一个神经元的数学原理，当把神经元的个数增多之后，原理以此类推，只不过是要增加权重<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font>以及输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>X</strong></font></font>的个数而已。</p><p><strong>下边就可以看作是一个，含有两层的神经网络结构。</strong><br><a href="https://imgtu.com/i/ImCAud"><img src="https://z3.ax1x.com/2021/11/04/ImCAud.md.png" alt="ImCAud.md.png"></a></p><ul><li>第一层节点： <font style='background:#F6E1E7'><font color="#D83B64"><strong>11</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>12</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>13</strong></font></font> 。第二层节点： <font style='background:#F6E1E7'><font color="#D83B64"><strong>21</strong></font></font> 。</li><li>输入： <font style='background:#F6E1E7'><font color="#D83B64"><strong>X1</strong></font></font> ，<font style='background:#F6E1E7'><font color="#D83B64"><strong>X2</strong></font></font> 。 输出 ：<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font> 。<br><br>遇是，根据公式：<strong>输出</strong>等于<strong>输入</strong>作用于<strong>权重</strong>，得出以下推导：</li><li>输入：<font style='background:#F6E1E7'><font color="#D83B64"><strong>X1</strong></font></font>，<font style='background:#F6E1E7'><font color="#D83B64"><strong>X2</strong></font></font>.</li><li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>11</strong></font></font>的值：<a href="https://imgtu.com/i/ImPEzF"><img src="https://z3.ax1x.com/2021/11/04/ImPEzF.png" alt="ImPEzF.png"></a></li><li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>12</strong></font></font>的值：<a href="https://imgtu.com/i/ImP3RO"><img src="https://z3.ax1x.com/2021/11/04/ImP3RO.png" alt="ImP3RO.png"></a></li><li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>13</strong></font></font>的值：<a href="https://imgtu.com/i/ImPYsH"><img src="https://z3.ax1x.com/2021/11/04/ImPYsH.png" alt="ImPYsH.png"></a></li><li>节点<font style='background:#F6E1E7'><font color="#D83B64"><strong>21</strong></font></font>的值就是最终输出<font style='background:#F6E1E7'><font color="#D83B64"><strong>Y</strong></font></font>：<a href="https://imgtu.com/i/ImikTI"><img src="https://z3.ax1x.com/2021/11/04/ImikTI.png" alt="ImikTI.png"></a></li></ul><p><strong>所以，最终的整合式子为：</strong><br><a href="https://imgtu.com/i/ImFXRK"><img src="https://z3.ax1x.com/2021/11/04/ImFXRK.png" alt="ImFXRK.png"></a></p><p><strong>于是，我们可以发现，类似于这样的堆叠方式，我们可以组合成很多的数学函数。</strong></p><blockquote><p>这就是神经网络，他的目的在于将数学公式堆砌出来，至于为什么要这样堆砌，是因为<strong>这样堆砌计算机计算比较方便</strong>呗。</p></blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>到目前为止你已经知道了神经网络的由来，并且知道神经网络与数学公式之间的关系。</p><p><strong>此时你需要明确的知识点是：</strong></p><ul><li><strong>人工智能就是使用已有的数据，拟合出一个可以用来预测未来的公式。</strong></li><li><strong>这个公式的系数需要一直调整，从而找出一组最为合适，正确率较高的系数。</strong></li><li><strong>因为系数的寻找需要大量的计算，所以需要将这个公式用神经网络表示出来的，因为在计算机中这样表示的时候计算最为方便。</strong></li></ul><h2 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a><strong>监督学习与无监督学习</strong></h2><blockquote><p>这个知识点比较简单，就一些单纯的概念。</p></blockquote><p><strong>监督学习：</strong> 就是我们收集到的数据是有标签的。</p><blockquote><p>就是说，我们收集到的数据是已经分好类的。<br><br>比如说：当前当前有一批样本数据，</p></blockquote><ul><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>x1, x2, x6, x9, x13</strong></font></font>属于类别<font style='background:#F6E1E7'><font color="#D83B64"><strong>y1</strong></font></font>类。</li><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>x3, x4, x5, x8, x11</strong></font></font>属于类别<font style='background:#F6E1E7'><font color="#D83B64"><strong>y2</strong></font></font>类。</li><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>x7, x10, x12</strong></font></font>属于类别<font style='background:#F6E1E7'><font color="#D83B64"><strong>y3</strong></font></font>类。</li></ul><p>然后接下来我们使用这些数据的时候，就可以使用已有标签的数据，去拟合出曲线，用以预测未来。</p><p><strong>无监督学习：</strong> 我们收集到的数据是无标签的。</p><blockquote><p>就是说，收集到的数据并没有固定的类别，我们需要做的事情就是挖掘数据内部的联系，给他们聚类，找出类别。</p></blockquote><p><a href="https://imgtu.com/i/ImE6VH"><img src="https://z3.ax1x.com/2021/11/04/ImE6VH.png" alt="ImE6VH.png"></a></p><p>如图所示，挖掘出数据内部的联系，让他自动归类。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h2><blockquote><p>上边解释过了，损失函数的作用就是计算 <strong>真实值</strong> 与 <strong>预测值</strong> 之间距离的 （距离其实可以简单理解为两个数据之间的差距）。</p></blockquote><p>这里介绍一些常见的几种损失函数，以供大家入门使用。</p><h3 id="一些前提"><a href="#一些前提" class="headerlink" title="一些前提"></a><strong>一些前提</strong></h3><blockquote><p>这里给定一些大前提，下边的几种损失函数通用的那种。</p></blockquote><ul><li><strong>真实值：</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font> ，他就是针对某一组输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>的真实标签。</li><li><strong>预测值：</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>，他就是针对输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>的预测标签。</li><li><strong>样本数：</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font>，他就是我们每次输入多少样本进行计算，比如：某一次输入<font style='background:#F6E1E7'><font color="#D83B64"><strong>5</strong></font></font>组<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>，得到<font style='background:#F6E1E7'><font color="#D83B64"><strong>5</strong></font></font>个预测结果，这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>m=5</strong></font></font>.</li></ul><h3 id="绝对值损失函数"><a href="#绝对值损失函数" class="headerlink" title="绝对值损失函数"></a><strong>绝对值损失函数</strong></h3><blockquote><p>其实就是简单的计算 真实值 与 预测值 之间的绝对值距离而已。</p></blockquote><p><strong>公式：</strong><br><a href="https://imgtu.com/i/ImVOTH"><img src="https://z3.ax1x.com/2021/11/04/ImVOTH.png" alt="ImVOTH.png"></a></p><p><strong>解释：</strong></p><ul><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>J(y,f(x))</strong></font></font> 的意思就是，这个损失函数的参数是：真是标签<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font> 与 预测数据<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>  。</li><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>J(w,b)</strong></font></font> 的意思是，这个损失函数的目的是优化参数 <font style='background:#F6E1E7'><font color="#D83B64"><strong>w</strong></font></font> 与 <font style='background:#F6E1E7'><font color="#D83B64"><strong>b</strong></font></font> 。这里的<font style='background:#F6E1E7'><font color="#D83B64"><strong>w</strong></font></font> ，<font style='background:#F6E1E7'><font color="#D83B64"><strong>b</strong></font></font> 其实就是系数的矩阵形式。</li><li>后边具体的计算公式就是：输入有<font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font> 个样本，计算出这<font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font> 个样本的距离绝对值和，然后再求均值。</li></ul><h3 id="均方差损失函数"><a href="#均方差损失函数" class="headerlink" title="均方差损失函数"></a><strong>均方差损失函数</strong></h3><blockquote><p>就是将上边式子的绝对值换成平方就好了。</p></blockquote><p><strong>公式：</strong><br><a href="https://imgtu.com/i/Imm9eS"><img src="https://z3.ax1x.com/2021/11/04/Imm9eS.png" alt="Imm9eS.png"></a></p><p><strong>解释：</strong></p><ul><li>这里只是将绝对值换成了平方，除以<font style='background:#F6E1E7'><font color="#D83B64"><strong>m</strong></font></font>换成了除以<font style='background:#F6E1E7'><font color="#D83B64"><strong>2m</strong></font></font>。</li></ul><h3 id="交叉熵损失函数"><a href="#交叉熵损失函数" class="headerlink" title="交叉熵损失函数"></a><strong>交叉熵损失函数</strong></h3><blockquote><p>这个就比较麻烦了，交叉熵损失函数一般用于解决分类问题。</p></blockquote><p><strong>标签：</strong></p><p>在通常的分类问题中，标签<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>的取值一般只有 <font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font> 或 <font style='background:#F6E1E7'><font color="#D83B64"><strong>1</strong></font></font> 。</p><blockquote><p>1 表示是当前类别， 0 表示不是当前类别。</p></blockquote><p><strong>公式：</strong><br><a href="https://imgtu.com/i/Imnp11"><img src="https://z3.ax1x.com/2021/11/04/Imnp11.md.png" alt="Imnp11.md.png"></a></p><p><strong>解释：</strong></p><ul><li><p>上边说了，<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>与 <font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font> 都只能取 <font style='background:#F6E1E7'><font color="#D83B64"><strong>1</strong></font></font>与 <font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font>f 中的一种可能性。所以，上述公式的效果就是：</p></li><li><p><strong>如果 y与 f(x) 相同，则 J = 0.</strong></p></li></ul><blockquote><p>你带入<font style='background:#F6E1E7'><font color="#D83B64"><strong>y=1 , f(x)=1</strong></font></font> 试试就知道了。</p></blockquote><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>到这里你已经学习了三种常见的损失函数。</p><p><strong>此时你应该有一个明确的知识点就是：</strong></p><ul><li><strong>损失函数是用来计算真实值与预测值之间距离的。</strong></li><li><strong>当损失函数的值越小就代表着真实值与预测值之间的距离就越小，也就意味着预测的越准。</strong></li></ul><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a><strong>梯度下降</strong></h2><blockquote><p>好了好了，上边过完理论知识，这里来一个真真正正的数学内容了，其实不难，看我慢慢分析。</p></blockquote><ul><li>上边我们提到对数学函数优化的时候，只是介绍了理论的知识。</li></ul><blockquote><p>我们知道了损失函数就是衡量预测值与真实值之间距离的公式。<br><br>并且知道，损失函数的值越小，真实值和预测值之间的距离越小，也即：预测的越准。</p></blockquote><ul><li>但是并没有带着大家深入探究如何优化。</li></ul><blockquote><p>也就是没有告诉大家怎么使得损失函数的值越来越小。</p></blockquote><p><strong>其实，这里使用的数学知识就是 ：求偏导</strong></p><h3 id="数学例子"><a href="#数学例子" class="headerlink" title="数学例子"></a><strong>数学例子</strong></h3><blockquote><p>这里以一个简单的数学例子来引入梯度下降的内容。</p></blockquote><ul><li><strong>场景引入</strong></li></ul><blockquote><p>在数学课中我们经常做的一个题型就是：已知一个函数<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>的表达式，如何求出这个式子的最小值点。</p></blockquote><p>在数学题中我们经常用的方法就是：将函数<font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>对<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>求导，然后令导数式子为0，求出此时的x的值，即为最小值点的位置。</p><ul><li><strong>具体例子</strong></li></ul><blockquote><p>求函数<a href="https://imgtu.com/i/ImuwRA"><img src="https://z3.ax1x.com/2021/11/04/ImuwRA.png" alt="ImuwRA.png"></a>的最小值点，并且求出最小值。</p></blockquote><p><strong>对函数求导</strong><br><a href="https://imgtu.com/i/ImugIg"><img src="https://z3.ax1x.com/2021/11/04/ImugIg.png" alt="ImugIg.png"></a></p><p><strong>令导函数为0，求出此时的x</strong><br><a href="https://imgtu.com/i/ImuWGj"><img src="https://z3.ax1x.com/2021/11/04/ImuWGj.png" alt="ImuWGj.png"></a></p><p>此时，<font style='background:#F6E1E7'><font color="#D83B64"><strong>x=3</strong></font></font>即为函数 <font style='background:#F6E1E7'><font color="#D83B64"><strong>f(x)</strong></font></font>的最小值点，带入原方程 <font style='background:#F6E1E7'><font color="#D83B64"><strong>f(3)= 2<em>9-12</em>3+20 = 2</strong></font></font>.</p><blockquote><p>这个解题过程，想必大家都很熟悉吧。</p></blockquote><p><strong>下边就分析一下这个过程的数学原理了</strong></p><h3 id="数学例子原理"><a href="#数学例子原理" class="headerlink" title="数学例子原理"></a><strong>数学例子原理</strong></h3><blockquote><p>梯度就是导数。</p></blockquote><p>针对上边提到的方程的最小值求解，其实就是求出其梯度（导数）为0的位置，就是其最低点的位置。具体看下图：</p><ul><li>方程<a href="https://imgtu.com/i/ImuXW9"><img src="https://z3.ax1x.com/2021/11/04/ImuXW9.png" alt="ImuXW9.png"></a>图像如下：<br><a href="https://imgtu.com/i/ImuxQ1"><img src="https://z3.ax1x.com/2021/11/04/ImuxQ1.png" alt="ImuxQ1.png"></a></li></ul><blockquote><p>从图中可以看出，方程在不同位置的导数方向是不同的，只有在最低点的位置，导数为<font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font>，所以可以用导数为<font style='background:#F6E1E7'><font color="#D83B64"><strong>0</strong></font></font>的位置求出最低点。</p></blockquote><p><strong>上边举的例子是一个比较简单的例子，方程中只有一个未知数，但是在真实情况中，往往一个方程有很多未知数。</strong></p><ul><li>比如：<a href="https://imgtu.com/i/ImKFFe"><img src="https://z3.ax1x.com/2021/11/04/ImKFFe.png" alt="ImKFFe.png"></a></li></ul><blockquote><p>此时需要做的事情就是针对每一个变量求偏导，<strong>求出该方程针对每个变量的梯度方向</strong> （梯度方向就是数据变小的方向）。</p></blockquote><p><strong>于是，在方程的每个点上，都有多个梯度方向，最终将这多个方向合并，形成这个点的最终梯度方向 （数据变小的方向）</strong><br><a href="https://imgtu.com/i/ImKZQI"><img src="https://z3.ax1x.com/2021/11/04/ImKZQI.png" alt="ImKZQI.png"></a></p><blockquote><p>如图，方程有两个变量<font style='background:#F6E1E7'><font color="#D83B64"><strong>x</strong></font></font>,<font style='background:#F6E1E7'><font color="#D83B64"><strong>y</strong></font></font>，于是在A点针对两个变量求偏导就可以得到各自的梯度方向（两个红色箭头的方向）。<br><br>然后，将两个梯度进行合并，得到最终的梯度方向<font style='background:#F6E1E7'><font color="#D83B64"><strong>Z</strong></font></font> 。<strong>Z方向就是方程在A点数据变小的方向了。</strong></p></blockquote><h3 id="完整例子"><a href="#完整例子" class="headerlink" title="完整例子"></a><strong>完整例子</strong></h3><blockquote><p>上边讲完原理，这里就举出一个例子，带着大家走一遍梯度下降找最小值的过程。</p></blockquote><p>假设此时的方程已知，并且根据方程绘制出的图像如下。<br><a href="https://imgtu.com/i/ImKtO0"><img src="https://z3.ax1x.com/2021/11/04/ImKtO0.png" alt="ImKtO0.png"></a></p><ul><li>刚开始我们位于A点：</li></ul><blockquote><p>1、在A点处针对方程的各个变量求出偏导，于是便可以得到方程针对各个方向的梯度方向。<br><br>2、将A点处各个方向的梯度方向进行合并，形成最终的梯度方向。<br><br>3、最终的梯度方向就是AB方向。<br><br>4、于是向着AB方向走出一段距离，走到了B点。</p></blockquote><ul><li>到达B点： （思路同上）</li></ul><blockquote><p>1、求出B点处各个方向的梯度方向，然后合并所有梯度方向，得到最终的B点处梯度方向 BC。<br><br>2、于是沿着BC方向，走出一段距离，到达C点。</p></blockquote><ul><li>…重复上述过程：</li></ul><blockquote><p>到达某个点之后，求出各方向的偏导数，然后合并得到最终的梯度方向。<br><br>然后沿着合并后的梯度方向走出一段距离到达下一个点。<br><br>然后在一直重复……</p></blockquote><ul><li>到达K点：</li></ul><blockquote><p>K点就是最终的点，这就是优化得到的最重点。</p></blockquote><p><strong>这就是整个找最小点的可视化过程，但是其中提到更新的数学细节并没有提到，所以下边提一下用到的数学更新公式吧</strong></p><h3 id="更新公式"><a href="#更新公式" class="headerlink" title="更新公式"></a><strong>更新公式</strong></h3><blockquote><p>一般我们梯度下降更新的数据只有函数的系数，然后函数的系数可以分为两类：权重（W）+ 偏差（b）<br><br>所以，更新的时候也就针对这两个参数就好了。</p></blockquote><p><strong>变量定义：</strong></p><ul><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>w</strong></font></font> ： 方程的权重。 （可以简单理解为方程变量前面的系数）</li><li><font style='background:#F6E1E7'><font color="#D83B64"><strong>b</strong></font></font>  ：方程的偏差。 （可以简单理解为方程中的常数）</li></ul><blockquote><p>比如：<a href="https://imgtu.com/i/ImKxhQ"><img src="https://z3.ax1x.com/2021/11/04/ImKxhQ.png" alt="ImKxhQ.png"></a>中，<font style='background:#F6E1E7'><font color="#D83B64"><strong>2 , 1</strong></font></font> 就是权重，<font style='background:#F6E1E7'><font color="#D83B64"><strong>3</strong></font></font>就是偏差。</p></blockquote><p><strong>公式：</strong></p><ul><li>更新权重<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> ：<a href="https://imgtu.com/i/ImMn39"><img src="https://z3.ax1x.com/2021/11/04/ImMn39.png" alt="ImMn39.png"></a></li></ul><blockquote><p>原始点的权重是<a href="https://imgtu.com/i/ImMjDx"><img src="https://z3.ax1x.com/2021/11/04/ImMjDx.png" alt="ImMjDx.png"></a> ，原始点此时针对<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> 的梯度方向是<a href="https://imgtu.com/i/ImQp5D"><img src="https://z3.ax1x.com/2021/11/04/ImQp5D.png" alt="ImQp5D.png"></a>.<br><br><font style='background:#F6E1E7'><font color="#D83B64"><strong>α</strong></font></font>  就是一段距离长度（它就是我们上文一直提到的走一段距离）。<br><br>所以<a href="https://imgtu.com/i/ImQVqP"><img src="https://z3.ax1x.com/2021/11/04/ImQVqP.png" alt="ImQVqP.png"></a>  表达的含义就是沿着<font style='background:#F6E1E7'><font color="#D83B64">** W**</font></font> 的梯度走一段长度为 <font style='background:#F6E1E7'><font color="#D83B64"><strong>α</strong></font></font> 的距离。<br><br>然后 <strong>新的</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> 就是 <strong>旧的</strong><font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font> 减去那一段<strong>方向长度</strong>。</p></blockquote><ul><li>更新偏差：<a href="https://imgtu.com/i/ImllFO"><img src="https://z3.ax1x.com/2021/11/04/ImllFO.png" alt="ImllFO.png"></a></li></ul><blockquote><p>原理同<font style='background:#F6E1E7'><font color="#D83B64"><strong>W</strong></font></font>.</p></blockquote><p><strong>这就是更新参数的整个梯度下降过程了。</strong></p><h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>到目前为止，基础的人工智能知识已经基本讲完了，这个时候我们再来仔细品味这句话。</p><p><strong>针对特定的任务，找出合适的数学表达式，然后一直优化表达式，直到这个表达式可以用来预测未来。</strong></p><p>或许你就会有不一样的体会了。</p><p><font face="微软雅黑" size=0.3><em>参考文献：<a href="https://www.cnblogs.com/xiaoxiaojiea/p/14637326.html">https://www.cnblogs.com/xiaoxiaojiea/p/14637326.html</a></em></font></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 进入深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征工程-特征降维</title>
      <link href="2021/09/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/"/>
      <url>2021/09/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程-特征降维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征工程-特征预处理</title>
      <link href="2021/09/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/"/>
      <url>2021/09/20/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="什么是特征预处理"><a href="#什么是特征预处理" class="headerlink" title="什么是特征预处理"></a>什么是特征预处理</h1><h2 id="特征预处理定义"><a href="#特征预处理定义" class="headerlink" title="特征预处理定义"></a>特征预处理定义</h2><blockquote><p>scikit-learn的解释<br>provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.</p></blockquote><p>翻译过来：通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程<br><a href="https://imgtu.com/i/4nq3Ed"><img src="https://z3.ax1x.com/2021/09/16/4nq3Ed.md.png" alt="4nq3Ed.md.png"></a></p><ul><li>为什么我们要进行归一化/标准化？<ul><li><font color=#f0e68c>特征的单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，容易影响（支配）目标结果，使得一些算法无法学习到其它的特征</font></li></ul></li></ul><p>举例：约会对象数据<br><a href="https://imgtu.com/i/4nLjS0"><img src="https://z3.ax1x.com/2021/09/16/4nLjS0.md.png" alt="4nLjS0.md.png"></a></p><p>我们需要用到一些方法进行<font color=#f0e68c>无量纲化</font>，使不同规格的数据转换到同一规格.</p><h2 id="包含内容-数值型数据的无量纲化"><a href="#包含内容-数值型数据的无量纲化" class="headerlink" title="包含内容(数值型数据的无量纲化)"></a>包含内容(数值型数据的无量纲化)</h2><ul><li>归一化</li><li>标准化<h2 id="特征处理API"><a href="#特征处理API" class="headerlink" title="特征处理API"></a>特征处理API</h2><blockquote><p>sklearn.preprocessing</p></blockquote></li></ul><h1 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>通过对原始数据进行变换把数据映射到(默认为[0,1])之间</p><h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h2><p><a href="https://imgtu.com/i/4nXc8I"><img src="https://z3.ax1x.com/2021/09/16/4nXc8I.md.png" alt="4nXc8I.md.png"></a></p><blockquote><p>作用于每一列，max为一列的最大值，min为一列的最小值,那么X’’为最终结果，mx，mi分别为指定区间值默认mx为1,mi为0</p></blockquote><p><a href="https://imgtu.com/i/4nX5Vg"><img src="https://z3.ax1x.com/2021/09/16/4nX5Vg.md.png" alt="4nX5Vg.md.png"></a></p><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><blockquote><p>sklearn.preprocessing.MinMaxScaler (feature_range=(0,1)… )</p></blockquote><ul><li>MinMaxScalar.fit_transform(X)<br>X:numpy array格式的数据[n_samples,n_features]</li><li>返回值：转换后的形状相同的array <h2 id="数据计算"><a href="#数据计算" class="headerlink" title="数据计算"></a>数据计算</h2>我们对以下数据进行运算，保存的就是之前的约会对象数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">40920,8.326976,0.953952,3</span><br><span class="line">14488,7.153469,1.673904,2</span><br><span class="line">26052,1.441871,0.805124,1</span><br><span class="line">75136,13.147394,0.428964,1</span><br><span class="line">38344,1.669788,0.134296,1</span><br></pre></td></tr></table></figure></li><li>分析</li></ul><ol><li>实例化MinMaxScalar</li><li>通过fit_transform转换<figure class="highlight plain"><figcaption><span>pandas as pd</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line"></span><br><span class="line">def minmax_demo():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    归一化演示</span><br><span class="line">    :return: None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data &#x3D; pd.read_csv(&quot;.&#x2F;data&#x2F;dating.txt&quot;)</span><br><span class="line">    print(data)</span><br><span class="line">    # 1、实例化一个转换器类</span><br><span class="line">    transfer &#x3D; MinMaxScaler(feature_range&#x3D;(2, 3)) # 2-3之间</span><br><span class="line">    # 2、调用fit_transform</span><br><span class="line">    data &#x3D; transfer.fit_transform(data[[&#39;milage&#39;,&#39;Liters&#39;,&#39;Consumtime&#39;]])</span><br><span class="line">    print(&quot;最小值最大值归一化处理的结果：\n&quot;, data)</span><br><span class="line"></span><br><span class="line">    return None</span><br></pre></td></tr></table></figure></li><li>返回结果<figure class="highlight plain"><figcaption><span>Liters  Consumtime  target</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">0     40920   8.326976    0.953952       3</span><br><span class="line">1     14488   7.153469    1.673904       2</span><br><span class="line">2     26052   1.441871    0.805124       1</span><br><span class="line">3     75136  13.147394    0.428964       1</span><br><span class="line">..      ...        ...         ...     ...</span><br><span class="line">998   48111   9.134528    0.728045       3</span><br><span class="line">999   43757   7.882601    1.332446       3</span><br><span class="line"></span><br><span class="line">[1000 rows x 4 columns]</span><br><span class="line">最小值最大值归一化处理的结果：</span><br><span class="line"> [[ 2.44832535  2.39805139  2.56233353]</span><br><span class="line"> [ 2.15873259  2.34195467  2.98724416]</span><br><span class="line"> [ 2.28542943  2.06892523  2.47449629]</span><br><span class="line"> ..., </span><br><span class="line"> [ 2.29115949  2.50910294  2.51079493]</span><br><span class="line"> [ 2.52711097  2.43665451  2.4290048 ]</span><br><span class="line"> [ 2.47940793  2.3768091   2.78571804]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="归一化总结"><a href="#归一化总结" class="headerlink" title="归一化总结"></a>归一化总结</h2>因为最大值最小值是变化的，另外，最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差（健壮性），只适合传统精确小数据场景。怎么办？</li></ol><h1 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>通过对原始数据进行变换把数据变换到均值为0,标准差为1范围内</p><h2 id="公式-1"><a href="#公式-1" class="headerlink" title="公式"></a>公式</h2><p><a href="https://imgtu.com/i/4JE6tU"><img src="https://z3.ax1x.com/2021/09/20/4JE6tU.png" alt="4JE6tU.png"></a></p><blockquote><p>作用于每一列，mean为平均值，σ为标准差</p></blockquote><p>所以回到刚才异常点的地方，我们再来看看标准化<br><a href="https://imgtu.com/i/4JEHhD"><img src="https://z3.ax1x.com/2021/09/20/4JEHhD.md.png" alt="4JEHhD.md.png"></a></p><ul><li>对于归一化来说：如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变</li><li>对于标准化来说：如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。</li></ul><h2 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h2><ul><li><font color= red size=4>sklearn.preprocessing.StandardScaler( ) </font><ul><li>处理之后每列来说所有数据都聚集在均值0附近标准差差为1</li><li>StandardScaler.fit_transform(X)<ul><li>X:numpy array格式的数据[n_samples,n_features]</li></ul></li><li>返回值：转换后的形状相同的array</li></ul></li></ul><h2 id="数据计算-1"><a href="#数据计算-1" class="headerlink" title="数据计算"></a>数据计算</h2><p>同样对上面的数据进行处理</p><ul><li>分析<ol><li>实例化StandardScaler</li><li>通过fit_transform转换<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">def stand_demo():</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    标准化演示</span><br><span class="line">    :return: None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    data &#x3D; pd.read_csv(&quot;dating.txt&quot;)</span><br><span class="line">    print(data)</span><br><span class="line">    # 1、实例化一个转换器类</span><br><span class="line">    transfer &#x3D; StandardScaler()</span><br><span class="line">    # 2、调用fit_transform</span><br><span class="line">    data &#x3D; transfer.fit_transform(data[[&#39;milage&#39;,&#39;Liters&#39;,&#39;Consumtime&#39;]])</span><br><span class="line">    print(&quot;标准化的结果:\n&quot;, data)</span><br><span class="line">    print(&quot;每一列特征的平均值：\n&quot;, transfer.mean_)</span><br><span class="line">    print(&quot;每一列特征的方差：\n&quot;, transfer.var_)</span><br><span class="line"></span><br><span class="line">    return None</span><br><span class="line"></span><br></pre></td></tr></table></figure>返回结果：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">     milage     Liters  Consumtime  target</span><br><span class="line">0     40920   8.326976    0.953952       3</span><br><span class="line">1     14488   7.153469    1.673904       2</span><br><span class="line">2     26052   1.441871    0.805124       1</span><br><span class="line">..      ...        ...         ...     ...</span><br><span class="line">997   26575  10.650102    0.866627       3</span><br><span class="line">998   48111   9.134528    0.728045       3</span><br><span class="line">999   43757   7.882601    1.332446       3</span><br><span class="line"></span><br><span class="line">[1000 rows x 4 columns]</span><br><span class="line">标准化的结果:</span><br><span class="line"> [[ 0.33193158  0.41660188  0.24523407]</span><br><span class="line"> [-0.87247784  0.13992897  1.69385734]</span><br><span class="line"> [-0.34554872 -1.20667094 -0.05422437]</span><br><span class="line"> ..., </span><br><span class="line"> [-0.32171752  0.96431572  0.06952649]</span><br><span class="line"> [ 0.65959911  0.60699509 -0.20931587]</span><br><span class="line"> [ 0.46120328  0.31183342  1.00680598]]</span><br><span class="line">每一列特征的平均值：</span><br><span class="line"> [  3.36354210e+04   6.55996083e+00   8.32072997e-01]</span><br><span class="line">每一列特征的方差：</span><br><span class="line"> [  4.81628039e+08   1.79902874e+01   2.46999554e-01]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="标准化总结"><a href="#标准化总结" class="headerlink" title="标准化总结"></a>标准化总结</h2>在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 特征工程-特征预处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据处理与特征工程-特征提取</title>
      <link href="2021/06/09/%E8%BF%9B%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>2021/06/09/%E8%BF%9B%E5%85%A5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script>console.error("Error: [hexo-tag-aplayer] Meting support is disabled, cannot resolve the meting tags properly.");</script><h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><h2 id="可用数据集"><a href="#可用数据集" class="headerlink" title="可用数据集"></a>可用数据集</h2><ul><li>公司内部、百度</li><li>数据接口（￥）</li><li>各种数据集</li><li>学习阶段可用的数据集<ul><li><a href="https://scikit-learn.org/stable/#">sklean</a></li><li><a href="https://www.kaggle.com/">kaggle</a></li><li><a href="http://archive.ics.uci.edu/ml/datasets.php">UCI</a><h2 id="sklearn-数据集"><a href="#sklearn-数据集" class="headerlink" title="sklearn 数据集"></a>sklearn 数据集</h2></li></ul></li></ul><ol><li>导入数据集和工具库  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#导入sklearn数据包</span><br><span class="line">from sklearn.datasets import load_iris #导入鸢尾花数据集</span><br><span class="line">from sklearn.model_selection import train_test_split #导入模型划分</span><br></pre></td></tr></table></figure></li><li>数据查看 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#字典格式</span><br><span class="line">total&#x3D;load_iris()</span><br><span class="line">#print(total)</span><br><span class="line">#数据目标值</span><br><span class="line">print(total.target_names)</span><br><span class="line">print(total.target)</span><br><span class="line">#数据内容（数据特征值）</span><br><span class="line">print(total.feature_names)</span><br><span class="line">print(total.data)</span><br><span class="line">#数据描述</span><br><span class="line">print(total.DESCR)</span><br></pre></td></tr></table></figure></li><li>对数据集进行划分 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#返回值 训练集 和 测试集</span><br><span class="line">x_train,x_test,y_train,y_test&#x3D;train_test_split(total.data,total.target,test_size&#x3D;0.24,random_state&#x3D;25)</span><br><span class="line">print(&quot;训练集特征值及目标值：\n&quot;,x_train,&quot;\n&quot;,y_train)</span><br><span class="line">print(&quot;测试集特征值及目标值：\n&quot;,x_test,x_train)</span><br></pre></td></tr></table></figure><h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><a href="https://imgtu.com/i/4nqt8P"><img src="https://z3.ax1x.com/2021/09/16/4nqt8P.md.png" alt="4nqt8P.md.png"></a></li></ol><h2 id="为什么需要特征工程"><a href="#为什么需要特征工程" class="headerlink" title="为什么需要特征工程"></a>为什么需要特征工程</h2><blockquote><p>数据和特征决定了机器学习的上限，而模型和算法知识逼近这个上限而已</p></blockquote><h2 id="什么是特征工程"><a href="#什么是特征工程" class="headerlink" title="什么是特征工程"></a>什么是特征工程</h2><blockquote><p>pandas ——&gt; 数据清洗、数据处理<br>sklearn  ——&gt; 特征工程</p></blockquote><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>将任意数据（如文本或图像）转化为可用于机器学习的数字特征</p><blockquote><p>注：特征值化是为了计算机更好的理解数据<br>sklearn.feature_extraction（特征提取API）</p></blockquote><ul><li>特征提取的分类<ul><li>字典特征提取（特征离散化）</li><li>文本特征提取</li><li>图像特征提取（深度学习）</li></ul></li></ul><h3 id="字典特征提取"><a href="#字典特征提取" class="headerlink" title="字典特征提取"></a>字典特征提取</h3><blockquote><p>字典特征提取 ——&gt; 类型 ——&gt; one-hot编码</p></blockquote><ol><li>导入sklearn数据包<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_iris #导入鸢尾花数据集</span><br><span class="line">from sklearn.model_selection import train_test_split #导入模型划分</span><br><span class="line">from sklearn.feature_extraction import DictVectorizer #导入字典特征转换器</span><br></pre></td></tr></table></figure></li><li>利用转化器进行特征提取<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data&#x3D;[&#123;&#39;city&#39;:&#39;北京&#39;,&#39;temperature&#39;:100&#125;,</span><br><span class="line">     &#123;&#39;city&#39;:&#39;上海&#39;,&#39;temperature&#39;:60&#125;,</span><br><span class="line">     &#123;&#39;city&#39;:&#39;深圳&#39;,&#39;temperature&#39;:30&#125;]</span><br><span class="line">#1.实例化一个转化器类</span><br><span class="line">transfer&#x3D;DictVectorizer(sparse&#x3D;False)#sparse&#x3D;Ture 返回sparse矩阵（稀疏矩阵将非零值按位置返回）---&gt;可以提高效率</span><br><span class="line">#2.调用fit_transform()</span><br><span class="line">data_new&#x3D;transfer.fit_transform(data)</span><br><span class="line">print(transfer.get_feature_names())</span><br><span class="line">print(data_new)</span><br></pre></td></tr></table></figure><a href="https://imgtu.com/i/2yh0Nn"><img src="https://z3.ax1x.com/2021/06/09/2yh0Nn.png" alt="2yh0Nn.png"></a><h3 id="中文文本特征提取"><a href="#中文文本特征提取" class="headerlink" title="中文文本特征提取"></a>中文文本特征提取</h3></li></ol><h4 id="方法一：CountVectorizer"><a href="#方法一：CountVectorizer" class="headerlink" title="方法一：CountVectorizer"></a>方法一：CountVectorizer</h4><pre><code>统计每个样本特征词出现的个数stop_words停用词停用词表</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import CountVectorizer#导入文本特征转换器</span><br><span class="line"></span><br><span class="line">data&#x3D;[&quot;人生苦短我要学习深度学习，加油奥里给我里宝贝。&quot;,</span><br><span class="line">     &quot;菏泽曹县666窝里宝贝。&quot;,</span><br><span class="line">     &quot;我爱你桑桑。&quot;]</span><br><span class="line">data1&#x3D;&quot;我爱北京天安门&quot;</span><br><span class="line">#使用jieba切割文档（切割参数为字符串）</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">a&#x3D;list(jieba.cut(data1))</span><br><span class="line">b&#x3D;&quot; &quot;.join(list(jieba.cut(data1)))</span><br><span class="line">print(a)</span><br><span class="line">print(type(a))</span><br><span class="line">print(b)</span><br><span class="line">print(type(b))</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">#1.将中文文本进行分词</span><br><span class="line">data_new&#x3D;[]</span><br><span class="line">for sent in data:</span><br><span class="line">    #a&#x3D;&quot; &quot;.join(list(jieba.cut(sent)))</span><br><span class="line">    #print(a)</span><br><span class="line">    data_new.append(&quot; &quot;.join(list(jieba.cut(sent))))</span><br><span class="line">print(data_new)</span><br><span class="line"></span><br><span class="line">#2.实现一个转化器类</span><br><span class="line">transfer&#x3D;CountVectorizer(stop_words&#x3D;[&quot;666&quot;,&quot;宝贝啊&quot;])</span><br><span class="line">#3.调用fit_transform</span><br><span class="line">data_fin&#x3D;transfer.fit_transform(data_new)</span><br><span class="line">print(&quot;特征名字：\n&quot;,transfer.get_feature_names())</span><br><span class="line">print(&quot;data_fin：\n&quot;,data_fin.toarray())</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/2yhycT"><img src="https://z3.ax1x.com/2021/06/09/2yhycT.png" alt="2yhycT.png"></a></p><h4 id="方法二：TfidfVectorize"><a href="#方法二：TfidfVectorize" class="headerlink" title="方法二：TfidfVectorize"></a>方法二：TfidfVectorize</h4><pre><code>区别于方法一：更容易找到关键词（在其他文章出现很少，在本文中出现很多的词汇）TF —— 词频（term frequency）IDF —— 由总文件数目除以包括该词语之文件的数目，再到的商取以10为底的对数得到TF-IDF=TF×IDF —— 重要程度</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line"></span><br><span class="line">data&#x3D;[&quot;人生苦短我要学习深度学习，加油奥里给我里宝贝。&quot;,</span><br><span class="line">     &quot;菏泽曹县666窝里宝贝。&quot;,</span><br><span class="line">     &quot;我爱你桑桑。&quot;]</span><br><span class="line"></span><br><span class="line">#1.将文本进行分词</span><br><span class="line">data_new&#x3D;[]</span><br><span class="line">for sent in data:</span><br><span class="line">    data_new.append(&quot; &quot;.join(list(jieba.cut(sent))))</span><br><span class="line">#2.实例化一个转换器对象</span><br><span class="line">transfer&#x3D;TfidfVectorizer()</span><br><span class="line">#3.利用转换器对象进行数据分割</span><br><span class="line">data_fin&#x3D;transfer.fit_transform(data_new)</span><br><span class="line">print(&quot;特征名字：\n&quot;,transfer.get_feature_names())</span><br><span class="line">print(&quot;data_fin：\n&quot;,data_fin.toarray())</span><br></pre></td></tr></table></figure><p><a href="https://imgtu.com/i/2yhguF"><img src="https://z3.ax1x.com/2021/06/09/2yhguF.png" alt="2yhguF.png"></a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据处理与特征工程-特征提取 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>了解机器学习</title>
      <link href="2021/06/08/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>2021/06/08/%E4%BA%86%E8%A7%A3%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="人工智能概述"><a href="#人工智能概述" class="headerlink" title="人工智能概述"></a>人工智能概述</h1><h2 id="人工智能概述-1"><a href="#人工智能概述-1" class="headerlink" title="人工智能概述"></a>人工智能概述</h2><ul><li>达特茅斯会议-人工智能的起点</li><li>机器学习是人工智能的一个实现途径</li><li>深度学习是机器学习的一个方法发展而来<h2 id="机器学习、深度学习能做些什么"><a href="#机器学习、深度学习能做些什么" class="headerlink" title="机器学习、深度学习能做些什么"></a>机器学习、深度学习能做些什么</h2></li><li>传统预测</li><li>图像识别</li><li>自然语言处理</li></ul><h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><h2 id="机器学习定义"><a href="#机器学习定义" class="headerlink" title="机器学习定义"></a>机器学习定义</h2><p><em>机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测</em></p><h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p><strong>类似于人</strong><br><img src="https://z3.ax1x.com/2021/06/08/2sF9Ts.png"></p><h1 id="机器学习数据集"><a href="#机器学习数据集" class="headerlink" title="机器学习数据集"></a>机器学习数据集</h1><p><strong>结构：特征值+目标值</strong></p><p><img src="https://z3.ax1x.com/2021/06/08/2sAgFs.png" alt="2sAgFs.png"></p><h1 id="机器学习算法分类"><a href="#机器学习算法分类" class="headerlink" title="机器学习算法分类"></a>机器学习算法分类</h1><h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><ul><li><p>目标值：类别 —— 分类问题  </p><blockquote><p>具体算法：k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归</p></blockquote></li></ul><ul><li><p>目标值：连续性数据 —— 回归问题</p><blockquote><p>具体算法：线性回归、岭回归</p></blockquote></li></ul><h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><ul><li><p>目标值：无</p><blockquote><p>具体算法：k-means</p></blockquote></li></ul><h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><pre><code>  1.预测明天的气温是多少度？  回归  2.预测明天是阴、晴还是雨？  分类  3.人脸年龄预测？  分类（老小）/回归（具体年龄）  4.人脸识别？  分类</code></pre><h1 id="机器学习开发流程"><a href="#机器学习开发流程" class="headerlink" title="机器学习开发流程"></a>机器学习开发流程</h1><ol><li>获取数据</li><li>数据处理</li><li>特征工程</li><li>建立模型（算法训练）</li><li>模型评估</li><li>应用<br><img src="https://z3.ax1x.com/2021/06/08/2sZCRI.png" alt="2sZCRI.png"><br><img src="https://z3.ax1x.com/2021/06/08/2sZDOK.png" alt="2sZDOK.png"></li></ol><h1 id="学习框架和资料介绍"><a href="#学习框架和资料介绍" class="headerlink" title="学习框架和资料介绍"></a>学习框架和资料介绍</h1><ol><li><p>算法是核心、数据与计算是基础</p></li><li><p>找准定位</p><blockquote><p>大部分复杂模型的算法设计都是算法工程师在做，而我们做的是：</p><blockquote><ul><li>分析很多数据</li><li>分析具体的业务</li><li>应用常见的算法</li><li>特征工程、调参、优化</li></ul></blockquote></blockquote></li><li><p>怎么做？</p><ol><li>入门</li><li>实战类书记</li><li>机器学习（西瓜书） - 周志华<br>统计学习方法 - 李航<br>深度学习（花书） </li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 了解机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo博客搭建与优化</title>
      <link href="2021/01/14/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
      <url>2021/01/14/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="安装需要的软件"><a href="#安装需要的软件" class="headerlink" title="安装需要的软件"></a>安装需要的软件</h1><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><blockquote><p>我们需要安装nodejs、git bash、npm、Hexo<br>其中我们只需要下载前两个就行了</p></blockquote><p><a href="https://nodejs.org/en/">Nodejs下载地址</a></p><p><a href="https://www.git-scm.com/download/win">Git下载地址</a></p><p><a href="https://www.cnblogs.com/ximiaomiao/p/7140456.html">Git安装参考</a></p><p><a href="https://www.xuanfengge.com/using-ssh-key-link-github-photo-tour.html">Git配置参考</a></p><p>最新版的Nodejs中包含了npm，所以我们不需要额外的安装了</p><p>下载完之后无脑点<code>下一步</code>就可以了,哈哈是不是很简单呢？</p><p>我们打开<code>Git Bash</code>输入下面命令来检测安装是否成功</p><p><code>node -v</code>和<code>npm -v</code>如果没有问题的话，应该是这样字的。</p><p><a href="https://imgchr.com/i/saRoQO"><img src="https://s3.ax1x.com/2021/01/14/saRoQO.png" alt="saRoQO.png"></a></p><blockquote><p>我们启动cmd，输入以下两条命令，成功后之后通过npm全局安装的包都会存放到node_global文件夹(这个文件夹是我自己创建的,你也可以创建在不同位置)下，后续查找包较方便。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm config set prefix &quot;D:\Program Files\nodejs\node_global&quot;</span><br><span class="line"></span><br><span class="line">npm config set cache &quot;D:\Program Files\nodejs\node_cache&quot;</span><br></pre></td></tr></table></figure><p><strong><em>这里的路径要记住，接下来可能我们在配置环境变量的时候，还将会用到</em></strong></p><blockquote><p>检测没问题之后，我们安装最后一个东西hexo<br>打开<code>Git Bash</code>输入<code>npm install -g hexo</code><br>安装完之后的显示信息如下所示:</p></blockquote><p><a href="https://imgchr.com/i/safuCt"><img src="https://s3.ax1x.com/2021/01/14/safuCt.png" alt="safuCt.png"></a></p><p>但是如果你会发现Hexo无法使用,我们还需要配置环境变量</p><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>这步，可能会比较的难，你需要跟着我做。</p><blockquote><p>我的电脑右击属性-&gt;点高级系统配置-&gt;点环境变量-&gt;在最上边一栏双击Path-&gt;点击新建-&gt;然后输入你node_global的路径</p></blockquote><p>步骤如图所示:<br><a href="https://imgchr.com/i/safyVJ"><img src="https://s3.ax1x.com/2021/01/14/safyVJ.png" alt="safyVJ.png"></a><a href="https://imgchr.com/i/safR8x"><img src="https://s3.ax1x.com/2021/01/14/safR8x.png" alt="safR8x.png"></a><a href="https://imgchr.com/i/saffxK"><img src="https://s3.ax1x.com/2021/01/14/saffxK.png" alt="saffxK.png"></a></p><h1 id="开始秒建博客"><a href="#开始秒建博客" class="headerlink" title="开始秒建博客"></a>开始秒建博客</h1><p>准备工作做了这么多了，现在我们终于要开始搭建自己的博客了,进入一个你博客存放的位置,然后在命令行中输入<code>hexo init</code>,这是博客的初始化操作,紧接着我们休息片刻喝口水.<br>现在初始化完毕了，我们首先看看我们的博客长什么样子吧!我们在命令行中输入<code>hexo s</code>(s是start的意思),然后我们打开浏览器输入网址<code>localhost:4000</code>我们就可以看到自己的博客了，博客如下图所示:<br><a href="https://imgchr.com/i/safLGt"><img src="https://s3.ax1x.com/2021/01/14/safLGt.png" alt="safLGt.png"></a><br>这时候大家可能会说，这是什么垃圾博客，白给我都不要，走了走了，算了算了。<br>大哥们，咱们先简单配置一下并说说Hexo的基本用法，然后就美化一下，相信我，最后不会很垃圾的.</p><h2 id="简单配置一下博客"><a href="#简单配置一下博客" class="headerlink" title="简单配置一下博客"></a>简单配置一下博客</h2><p>博客的配置文件是<code>你博客的根目录的_config.yml</code>文件<br>然后我们打开文件,进行基本的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Site</span><br><span class="line">title: CharlesBlog        # 这里写博客的名字</span><br><span class="line">subtitle:     # 这里写博客的副标题</span><br><span class="line">description: &#39;&#39;         # 关于你博客的描述</span><br><span class="line">keywords:</span><br><span class="line">author: Charles            # 这里写博客的作者</span><br><span class="line">language: zh-CN         # 博客语言</span><br><span class="line">timezone: &#39;&#39;</span><br></pre></td></tr></table></figure><p>简单配置完毕，接来下我们学一下Hexo的基本命令</p><h3 id="Hexo基本命令"><a href="#Hexo基本命令" class="headerlink" title="Hexo基本命令"></a>Hexo基本命令</h3><table><thead><tr><th>命令</th><th>作用</th></tr></thead><tbody><tr><td>Hexo init</td><td>初始化博客</td></tr><tr><td>Hexo s</td><td>运行博客</td></tr><tr><td>Hexo n title</td><td>创建一篇新的文章，文章标题是title</td></tr><tr><td>Hexo c</td><td>清理文件</td></tr><tr><td>Hexo g</td><td>生成静态文件</td></tr><tr><td>Hexo d</td><td>程序部署博客（需要插件）</td></tr></tbody></table><h2 id="安装主题并简单配置"><a href="#安装主题并简单配置" class="headerlink" title="安装主题并简单配置"></a>安装主题并简单配置</h2><p><a href="https://butterfly.js.org/">butterfly主题</a></p><p><a href="https://hexo.io/themes/">Hexo官网主题</a></p><p>主题的预览图:<br><a href="https://imgchr.com/i/saoVh9"><img src="https://s3.ax1x.com/2021/01/14/saoVh9.md.png" alt="saoVh9.md.png"></a></p><blockquote><p>接下来执行<code>git clone https://github.com/jerryc127/hexo-theme-butterfly themes/butterfly</code>进行安装,这里我们先让他安装着，我们打开我们的配置文件找到这一行theme: landspace然后将landspace替换成我们的主题也就是butterfly</p></blockquote><blockquote><p>此时运行博客 是运行不了的，因为我们少了一个插件，我们通过命令<code>npm install hexo-renderer-pug hexo-renderer-stylus</code>来安装这个插件<br>最终完美运行.</p></blockquote><p><strong><em>为了以后升级方便，这里不推荐直接对主题的配置文件进行修改，而是复制配置文件进行修改。个人推荐把主題的配置文件<code>_config.yml</code>复制到 Hexo 的根目录下命名为<code>_config.butterfly.yml</code>，如果目录不存在那就创建一个。</em></strong></p><h3 id="配置主页大图片"><a href="#配置主页大图片" class="headerlink" title="配置主页大图片"></a>配置主页大图片</h3><p>安装完博客后我们看到的就是这个大图片<br><a href="https://imgchr.com/i/saIVQP"><img src="https://s3.ax1x.com/2021/01/14/saIVQP.md.png" alt="saIVQP.md.png"></a><br>你可能会说不好看，接下来我们进行更换这个图片，首先我们先找到一个自己想更换的图片,接下来我们将他放到图床当中去，本人经常用<a href="https://imgchr.com/">路过图床</a>,然后将我们的图片上传上去，这里会显示一个连接，我们先复制这个链接。<br><a href="https://imgchr.com/i/saot1I"><img src="https://s3.ax1x.com/2021/01/14/saot1I.md.png" alt="saot1I.md.png"></a></p><blockquote><p>然后找到我们的主题配置文件(路径应该是 博客根目录/_config.butterfly.yml),然后找到default_top_img:这一行将链接替换成你刚才复制的链接即可.</p></blockquote><p>说道这里我们顺便配置一下我们的头像，头像和首页图配置方法是一样的只要在配置文件中找到头像的位置将URL放入即可。</p><h3 id="配置主页的导航栏"><a href="#配置主页的导航栏" class="headerlink" title="配置主页的导航栏"></a>配置主页的导航栏</h3><p>我们可以看到我们的导航栏都是英文，我们可以自己手动修改。<a href="https://imgchr.com/i/saTuCj"><img src="https://s3.ax1x.com/2021/01/14/saTuCj.md.png" alt="saTuCj.md.png"></a></p><blockquote><p>我们打开我们的主题配置文档，路径在哪里我也就不用说了吧，在博客根目录/_config.butterfly.yml(最后一遍了)<br>配置文件开头就是我们的导航栏配置，默认配置如下</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">menu:</span><br><span class="line">  Home: &#x2F; || fa fa-home</span><br><span class="line">  Archives: &#x2F;archives&#x2F; || fa fa-archive</span><br><span class="line">  Tags: &#x2F;tags&#x2F; || fa fa-tags</span><br><span class="line">  Categories: &#x2F;categories&#x2F; || fa fa-folder-open</span><br><span class="line">  Link: &#x2F;link&#x2F; || fa fa-link</span><br><span class="line">  About: &#x2F;about&#x2F; || fa fa-heart</span><br><span class="line">  List||fa fa-list:</span><br><span class="line">    - Music || &#x2F;music&#x2F; || fa fa-music</span><br><span class="line">    - Movie || &#x2F;movies&#x2F; || fa fa-film</span><br></pre></td></tr></table></figure><p>最终我修改完成后如下所示:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">menu:</span><br><span class="line">  首页: &#x2F; || fas fa-home</span><br><span class="line">  归档: &#x2F;archives&#x2F; || fas fa-archive</span><br><span class="line">  标签: &#x2F;tags&#x2F; || fas fa-tags</span><br><span class="line">  分类: &#x2F;categories&#x2F; || fas fa-folder-open</span><br><span class="line">  清单||fas fa-list:</span><br><span class="line">    - Music || &#x2F;music&#x2F; || fas fa-music</span><br><span class="line">    - Movie || &#x2F;movies&#x2F; || fas fa-video</span><br><span class="line">  友情链接: &#x2F;link&#x2F; || fas fa-link</span><br><span class="line">  关于: &#x2F;about&#x2F; || fas fa-heart</span><br></pre></td></tr></table></figure><p>  相信聪明的你，一看就懂了</p><h3 id="主页名人名言"><a href="#主页名人名言" class="headerlink" title="主页名人名言"></a>主页名人名言</h3><blockquote><p>我们在主题配置文件中搜索 <code>Never put off till tomorrow what you can do today</code>然后我们将这句话改成<code>我不知道将去何方 但我已在路上</code>最终实现了替换的效果，并且我们还可以去掉上边的一句话</p></blockquote><p>我们还可以自动获取网络上的好句子，我们只需要将<code>source: false</code>换成下面你想选择的样式</p><ul><li>source: 1 #调用博天API <a href="https://api.btstu.cn/">https://api.btstu.cn/</a></li><li>source: 2 #调用一言API <a href="https://hitokoto.cn/">https://hitokoto.cn/</a></li><li>source: 3 #调用一句话API <a href="http://yijuzhan.com/">http://yijuzhan.com/</a></li><li>source: 4 #调用今日詩詞API <a href="https://www.jinrishici.com/">https://www.jinrishici.com/</a></li></ul><p><strong><em>这里要注意的是: 在显示的时候，会先实现网络获取的一句话，然后在获取本地设置的话</em></strong></p><p><a href="https://butterfly.js.org/posts/21cfbf15/">更多butterfly美化在这哦</a></p><h1 id="部署云端"><a href="#部署云端" class="headerlink" title="部署云端"></a>部署云端</h1><p>现在我们的博客，感觉已经很漂亮了，接下来我们部署云端让所有人看到我们的博客吧!!!</p><p>最后！我们需要额外的一个工具来帮助我们推到仓库上，那就是！那就是！那就是 <code>hexo-deployer-git</code>搞它！</p><blockquote><p>执行下面的命令，进行安装插件</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><h2 id="使用GitHub部署云端"><a href="#使用GitHub部署云端" class="headerlink" title="使用GitHub部署云端"></a>使用GitHub部署云端</h2><blockquote><p>我们在Github中建立一个仓库，其中仓库名字必须是xxx.github.ioxxx是你的Github名字,过程如图所示</p></blockquote><p><a href="https://imgchr.com/i/sd96Cq"><img src="https://s3.ax1x.com/2021/01/14/sd96Cq.md.png" alt="sd96Cq.md.png"></a></p><blockquote><p>接下来，打开我们的<code>博客配置文件</code>,找到下面的内容</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: &lt;你的仓库地址&gt; # https:&#x2F;&#x2F;github.com&#x2F;TJ-XiaJiaHao&#x2F;TJ-XiaJiaHao.github.io</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure><blockquote><p>然后写上你刚刚建立仓库的地址</p></blockquote><blockquote><p>执行下面的命令，进行远程部署到我们的Github的仓库<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  # 清理垃圾</span><br><span class="line">hexo clean</span><br><span class="line"># 推送到远端</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><br>浏览器访问：<a href="https://xxxxx.github.io/">https://xxxxx.github.io/</a> 即可看到效果。(把xxxx替换成的Github名字就可以了)例如我的是 <a href="https://ciks111.github.io/">https://ciks111.github.io/</a></p></blockquote><p><strong><em>不要着急，可能会有1-2分钟的延迟</em></strong></p><p>最终终于大工告成了  本文也就到此结束了.</p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo博客搭建 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
